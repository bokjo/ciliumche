root@kind-worker2:/# journalctl -u kubelet
-- Journal begins at Thu 2021-12-30 13:58:05 UTC, ends at Thu 2021-12-30 14:44:00 UTC. --
Dec 30 13:58:05 kind-worker2 systemd[1]: Condition check resulted in kubelet: The Kubernetes Node Agent being skipped.
Dec 30 13:58:54 kind-worker2 systemd[1]: Starting kubelet: The Kubernetes Node Agent...
Dec 30 13:58:54 kind-worker2 systemd[1]: Started kubelet: The Kubernetes Node Agent.
Dec 30 13:58:54 kind-worker2 kubelet[172]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Dec 30 13:58:54 kind-worker2 kubelet[172]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Dec 30 13:58:54 kind-worker2 kubelet[172]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Dec 30 13:58:54 kind-worker2 kubelet[172]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Dec 30 13:58:54 kind-worker2 kubelet[172]: I1230 13:58:54.724741     172 server.go:197] "Warning: For remote container runtime, --pod-infra-container-image is ignored in kubelet, which should be set in that remote runtime instead"
Dec 30 13:58:54 kind-worker2 kubelet[172]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Dec 30 13:58:54 kind-worker2 kubelet[172]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Dec 30 13:58:54 kind-worker2 kubelet[172]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Dec 30 13:58:54 kind-worker2 kubelet[172]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Dec 30 13:58:55 kind-worker2 kubelet[172]: I1230 13:58:55.554495     172 server.go:440] "Kubelet version" kubeletVersion="v1.21.1"
Dec 30 13:58:55 kind-worker2 kubelet[172]: I1230 13:58:55.554843     172 server.go:851] "Client rotation is on, will bootstrap in background"
Dec 30 13:58:55 kind-worker2 kubelet[172]: W1230 13:58:55.557658     172 manager.go:159] Cannot detect current cgroup on cgroup v2
Dec 30 13:58:55 kind-worker2 kubelet[172]: I1230 13:58:55.558032     172 dynamic_cafile_content.go:167] Starting client-ca-bundle::/etc/kubernetes/pki/ca.crt
Dec 30 13:59:00 kind-worker2 kubelet[172]: W1230 13:59:00.565435     172 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.571704     172 container_manager_linux.go:278] "Container manager verified user specified cgroup-root exists" cgroupRoot=[kubelet]
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.571793     172 container_manager_linux.go:283] "Creating Container Manager object based on Node Config" nodeConfig={RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: ContainerRuntime:remote CgroupsPerQOS:true CgroupRoot:/kubelet CgroupDriver:cgroupfs KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: ReservedSystemCPUs: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[]} QOSReserved:map[] ExperimentalCPUManagerPolicy:none ExperimentalTopologyManagerScope:container ExperimentalCPUManagerReconcilePeriod:10s ExperimentalMemoryManagerPolicy:None ExperimentalMemoryManagerReservedMemory:[] ExperimentalPodPidsLimit:-1 EnforceCPULimits:true CPUCFSQuotaPeriod:100ms ExperimentalTopologyManagerPolicy:none}
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.571817     172 topology_manager.go:120] "Creating topology manager with policy per scope" topologyPolicyName="none" topologyScopeName="container"
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.571829     172 container_manager_linux.go:314] "Initializing Topology Manager" policy="none" scope="container"
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.571841     172 container_manager_linux.go:319] "Creating device plugin manager" devicePluginEnabled=true
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.572295     172 remote_runtime.go:62] parsed scheme: ""
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.572344     172 remote_runtime.go:62] scheme "" not registered, fallback to default scheme
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.572373     172 passthrough.go:48] ccResolverWrapper: sending update to cc: {[{/run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.572382     172 clientconn.go:948] ClientConn switching balancer to "pick_first"
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.572421     172 remote_image.go:50] parsed scheme: ""
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.572427     172 remote_image.go:50] scheme "" not registered, fallback to default scheme
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.572441     172 passthrough.go:48] ccResolverWrapper: sending update to cc: {[{/run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.572446     172 clientconn.go:948] ClientConn switching balancer to "pick_first"
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.572542     172 kubelet.go:404] "Attempting to sync node with API server"
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.572560     172 kubelet.go:272] "Adding static pod path" path="/etc/kubernetes/manifests"
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.572587     172 kubelet.go:283] "Adding apiserver pod source"
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.572602     172 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Dec 30 13:59:00 kind-worker2 kubelet[172]: I1230 13:59:00.575002     172 kuberuntime_manager.go:222] "Container runtime initialized" containerRuntime="containerd" version="v1.5.2" apiVersion="v1alpha2"
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.573820     172 apiserver.go:52] "Watching apiserver"
Dec 30 13:59:01 kind-worker2 kubelet[172]: E1230 13:59:01.824777     172 aws_credentials.go:77] while getting AWS credentials NoCredentialProviders: no valid providers in chain. Deprecated.
Dec 30 13:59:01 kind-worker2 kubelet[172]:         For verbose messaging see aws.Config.CredentialsChainVerboseErrors
Dec 30 13:59:01 kind-worker2 kubelet[172]: W1230 13:59:01.825125     172 probe.go:268] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.825685     172 server.go:1190] "Started kubelet"
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.826196     172 server.go:149] "Starting to listen" address="0.0.0.0" port=10250
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.827237     172 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.827344     172 server.go:405] "Adding debug handlers to kubelet server"
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.828512     172 volume_manager.go:271] "Starting Kubelet Volume Manager"
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.828625     172 desired_state_of_world_populator.go:141] "Desired state populator starts to run"
Dec 30 13:59:01 kind-worker2 kubelet[172]: E1230 13:59:01.831448     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.831902     172 client.go:86] parsed scheme: "unix"
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.831939     172 client.go:86] scheme "unix" not registered, fallback to default scheme
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.831958     172 passthrough.go:48] ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.831965     172 clientconn.go:948] ClientConn switching balancer to "pick_first"
Dec 30 13:59:01 kind-worker2 kubelet[172]: E1230 13:59:01.842179     172 nodelease.go:49] "Failed to get node when trying to set owner ref to the node lease" err="nodes \"kind-worker2\" not found" node="kind-worker2"
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.921393     172 cpu_manager.go:199] "Starting CPU manager" policy="none"
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.921512     172 cpu_manager.go:200] "Reconciling" reconcilePeriod="10s"
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.921531     172 state_mem.go:36] "Initialized new in-memory state store"
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.923497     172 policy_none.go:44] "None policy: Start"
Dec 30 13:59:01 kind-worker2 kubelet[172]: E1230 13:59:01.929293     172 kubelet.go:2291] "Error getting node" err="node \"kind-worker2\" not found"
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.931807     172 kubelet_node_status.go:71] "Attempting to register node" node="kind-worker2"
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.936572     172 kubelet_node_status.go:74] "Successfully registered node" node="kind-worker2"
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.940994     172 manager.go:600] "Failed to retrieve checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.941798     172 plugin_manager.go:114] "Starting Kubelet Plugin Manager"
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.942610     172 kubelet_network_linux.go:56] "Initialized protocol iptables rules." protocol=IPv4
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.992963     172 kubelet_network_linux.go:56] "Initialized protocol iptables rules." protocol=IPv6
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.993012     172 status_manager.go:157] "Starting to sync pod status with apiserver"
Dec 30 13:59:01 kind-worker2 kubelet[172]: I1230 13:59:01.993029     172 kubelet.go:1846] "Starting kubelet main sync loop"
Dec 30 13:59:01 kind-worker2 kubelet[172]: E1230 13:59:01.993063     172 kubelet.go:1870] "Skipping pod synchronization" err="PLEG is not healthy: pleg has yet to be successful"
Dec 30 13:59:02 kind-worker2 kubelet[172]: I1230 13:59:02.029640     172 kuberuntime_manager.go:1044] "Updating runtime config through cri with podcidr" CIDR="10.244.2.0/24"
Dec 30 13:59:02 kind-worker2 kubelet[172]: I1230 13:59:02.030648     172 kubelet_network.go:76] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.244.2.0/24"
Dec 30 13:59:02 kind-worker2 kubelet[172]: E1230 13:59:02.031837     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 13:59:02 kind-worker2 kubelet[172]: I1230 13:59:02.094541     172 topology_manager.go:187] "Topology Admit Handler"
Dec 30 13:59:02 kind-worker2 kubelet[172]: I1230 13:59:02.229883     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/df203002-8228-48c0-996c-9b5c56790dcd-kube-proxy\") pod \"kube-proxy-nszmf\" (UID: \"df203002-8228-48c0-996c-9b5c56790dcd\") "
Dec 30 13:59:02 kind-worker2 kubelet[172]: I1230 13:59:02.229946     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/df203002-8228-48c0-996c-9b5c56790dcd-xtables-lock\") pod \"kube-proxy-nszmf\" (UID: \"df203002-8228-48c0-996c-9b5c56790dcd\") "
Dec 30 13:59:02 kind-worker2 kubelet[172]: I1230 13:59:02.229983     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/df203002-8228-48c0-996c-9b5c56790dcd-lib-modules\") pod \"kube-proxy-nszmf\" (UID: \"df203002-8228-48c0-996c-9b5c56790dcd\") "
Dec 30 13:59:02 kind-worker2 kubelet[172]: I1230 13:59:02.230007     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-9drdt\" (UniqueName: \"kubernetes.io/projected/df203002-8228-48c0-996c-9b5c56790dcd-kube-api-access-9drdt\") pod \"kube-proxy-nszmf\" (UID: \"df203002-8228-48c0-996c-9b5c56790dcd\") "
Dec 30 13:59:02 kind-worker2 kubelet[172]: I1230 13:59:02.230018     172 reconciler.go:157] "Reconciler: start to sync state"
Dec 30 13:59:05 kind-worker2 kubelet[172]: I1230 13:59:05.558166     172 transport.go:135] "Certificate rotation detected, shutting down client connections to start using new credentials"
Dec 30 13:59:06 kind-worker2 kubelet[172]: E1230 13:59:06.942830     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 13:59:11 kind-worker2 kubelet[172]: E1230 13:59:11.923190     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 13:59:16 kind-worker2 kubelet[172]: E1230 13:59:16.925128     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 13:59:21 kind-worker2 kubelet[172]: E1230 13:59:21.926744     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 13:59:26 kind-worker2 kubelet[172]: E1230 13:59:26.928897     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 13:59:31 kind-worker2 kubelet[172]: E1230 13:59:31.930644     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 13:59:36 kind-worker2 kubelet[172]: E1230 13:59:36.932328     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 13:59:41 kind-worker2 kubelet[172]: E1230 13:59:41.913120     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 13:59:46 kind-worker2 kubelet[172]: E1230 13:59:46.914737     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 13:59:51 kind-worker2 kubelet[172]: E1230 13:59:51.915945     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 13:59:56 kind-worker2 kubelet[172]: E1230 13:59:56.919828     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:00:01 kind-worker2 kubelet[172]: E1230 14:00:01.921240     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:00:06 kind-worker2 kubelet[172]: E1230 14:00:06.922484     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:00:11 kind-worker2 kubelet[172]: E1230 14:00:11.902531     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:00:16 kind-worker2 kubelet[172]: E1230 14:00:16.905497     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:00:21 kind-worker2 kubelet[172]: E1230 14:00:21.906986     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:00:26 kind-worker2 kubelet[172]: E1230 14:00:26.909001     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:00:31 kind-worker2 kubelet[172]: E1230 14:00:31.910518     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:00:36 kind-worker2 kubelet[172]: E1230 14:00:36.912518     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:00:41 kind-worker2 kubelet[172]: E1230 14:00:41.893740     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:00:46 kind-worker2 kubelet[172]: E1230 14:00:46.895201     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:00:51 kind-worker2 kubelet[172]: E1230 14:00:51.896033     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:00:56 kind-worker2 kubelet[172]: E1230 14:00:56.897464     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:01:01 kind-worker2 kubelet[172]: E1230 14:01:01.899103     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:01:06 kind-worker2 kubelet[172]: E1230 14:01:06.900750     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:01:11 kind-worker2 kubelet[172]: E1230 14:01:11.882380     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:01:16 kind-worker2 kubelet[172]: E1230 14:01:16.884102     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:01:21 kind-worker2 kubelet[172]: E1230 14:01:21.889854     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:01:26 kind-worker2 kubelet[172]: E1230 14:01:26.892220     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:01:31 kind-worker2 kubelet[172]: E1230 14:01:31.892985     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:01:36 kind-worker2 kubelet[172]: E1230 14:01:36.895445     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:01:41 kind-worker2 kubelet[172]: E1230 14:01:41.875880     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:01:46 kind-worker2 kubelet[172]: E1230 14:01:46.878563     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:01:51 kind-worker2 kubelet[172]: E1230 14:01:51.880089     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:01:56 kind-worker2 kubelet[172]: E1230 14:01:56.881981     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:02:01 kind-worker2 kubelet[172]: E1230 14:02:01.883732     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:02:06 kind-worker2 kubelet[172]: E1230 14:02:06.885212     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:02:11 kind-worker2 kubelet[172]: E1230 14:02:11.866741     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:02:16 kind-worker2 kubelet[172]: E1230 14:02:16.868511     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:02:21 kind-worker2 kubelet[172]: E1230 14:02:21.869822     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:02:26 kind-worker2 kubelet[172]: E1230 14:02:26.872022     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:02:31 kind-worker2 kubelet[172]: E1230 14:02:31.873511     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:02:36 kind-worker2 kubelet[172]: E1230 14:02:36.875408     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:02:41 kind-worker2 kubelet[172]: E1230 14:02:41.885160     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:02:46 kind-worker2 kubelet[172]: E1230 14:02:46.888087     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:02:51 kind-worker2 kubelet[172]: E1230 14:02:51.889102     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:02:56 kind-worker2 kubelet[172]: E1230 14:02:56.890761     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:03:01 kind-worker2 kubelet[172]: E1230 14:03:01.893000     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:03:06 kind-worker2 kubelet[172]: E1230 14:03:06.895279     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:03:11 kind-worker2 kubelet[172]: E1230 14:03:11.888346     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:03:16 kind-worker2 kubelet[172]: E1230 14:03:16.889293     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:03:21 kind-worker2 kubelet[172]: E1230 14:03:21.890409     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:03:26 kind-worker2 kubelet[172]: E1230 14:03:26.892245     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:03:31 kind-worker2 kubelet[172]: E1230 14:03:31.894033     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:03:36 kind-worker2 kubelet[172]: E1230 14:03:36.895887     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:03:41 kind-worker2 kubelet[172]: E1230 14:03:41.879215     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:03:46 kind-worker2 kubelet[172]: E1230 14:03:46.880716     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:03:51 kind-worker2 kubelet[172]: E1230 14:03:51.882340     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:03:56 kind-worker2 kubelet[172]: E1230 14:03:56.883973     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:04:01 kind-worker2 kubelet[172]: W1230 14:04:01.757689     172 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Dec 30 14:04:01 kind-worker2 kubelet[172]: E1230 14:04:01.885206     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:04:06 kind-worker2 kubelet[172]: E1230 14:04:06.887487     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:04:11 kind-worker2 kubelet[172]: E1230 14:04:11.868649     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:04:16 kind-worker2 kubelet[172]: E1230 14:04:16.871224     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:04:21 kind-worker2 kubelet[172]: E1230 14:04:21.873305     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:04:26 kind-worker2 kubelet[172]: E1230 14:04:26.875322     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:04:31 kind-worker2 kubelet[172]: E1230 14:04:31.878435     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:04:36 kind-worker2 kubelet[172]: E1230 14:04:36.879667     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:04:41 kind-worker2 kubelet[172]: E1230 14:04:41.859659     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:04:46 kind-worker2 kubelet[172]: E1230 14:04:46.861619     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:04:51 kind-worker2 kubelet[172]: E1230 14:04:51.862835     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:04:56 kind-worker2 kubelet[172]: E1230 14:04:56.864194     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:05:01 kind-worker2 kubelet[172]: E1230 14:05:01.866798     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:05:06 kind-worker2 kubelet[172]: E1230 14:05:06.869567     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:05:11 kind-worker2 kubelet[172]: E1230 14:05:11.849637     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:05:16 kind-worker2 kubelet[172]: E1230 14:05:16.850799     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:05:21 kind-worker2 kubelet[172]: E1230 14:05:21.852940     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:05:26 kind-worker2 kubelet[172]: E1230 14:05:26.854072     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:05:31 kind-worker2 kubelet[172]: E1230 14:05:31.855674     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:05:36 kind-worker2 kubelet[172]: E1230 14:05:36.857903     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:05:41 kind-worker2 kubelet[172]: E1230 14:05:41.838605     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:05:46 kind-worker2 kubelet[172]: E1230 14:05:46.840726     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:05:51 kind-worker2 kubelet[172]: E1230 14:05:51.842244     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:05:56 kind-worker2 kubelet[172]: E1230 14:05:56.843650     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:06:01 kind-worker2 kubelet[172]: E1230 14:06:01.845998     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:06:06 kind-worker2 kubelet[172]: E1230 14:06:06.848379     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:06:11 kind-worker2 kubelet[172]: E1230 14:06:11.829341     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:06:16 kind-worker2 kubelet[172]: E1230 14:06:16.831809     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:06:21 kind-worker2 kubelet[172]: E1230 14:06:21.833803     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:06:26 kind-worker2 kubelet[172]: E1230 14:06:26.835742     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:06:31 kind-worker2 kubelet[172]: E1230 14:06:31.837496     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:06:36 kind-worker2 kubelet[172]: E1230 14:06:36.839934     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:06:41 kind-worker2 kubelet[172]: E1230 14:06:41.820229     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:06:46 kind-worker2 kubelet[172]: E1230 14:06:46.823067     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:06:51 kind-worker2 kubelet[172]: E1230 14:06:51.824059     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:06:56 kind-worker2 kubelet[172]: E1230 14:06:56.825402     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:07:01 kind-worker2 kubelet[172]: E1230 14:07:01.827414     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:07:06 kind-worker2 kubelet[172]: E1230 14:07:06.827942     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:07:11 kind-worker2 kubelet[172]: E1230 14:07:11.808182     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:07:16 kind-worker2 kubelet[172]: E1230 14:07:16.810379     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:07:21 kind-worker2 kubelet[172]: E1230 14:07:21.811674     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:07:26 kind-worker2 kubelet[172]: E1230 14:07:26.813812     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:07:31 kind-worker2 kubelet[172]: E1230 14:07:31.815766     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:07:36 kind-worker2 kubelet[172]: E1230 14:07:36.817876     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:07:41 kind-worker2 kubelet[172]: E1230 14:07:41.798803     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:07:46 kind-worker2 kubelet[172]: E1230 14:07:46.800279     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:07:51 kind-worker2 kubelet[172]: E1230 14:07:51.802673     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:07:56 kind-worker2 kubelet[172]: E1230 14:07:56.804792     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:08:01 kind-worker2 kubelet[172]: E1230 14:08:01.806783     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:08:06 kind-worker2 kubelet[172]: E1230 14:08:06.808516     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:08:11 kind-worker2 kubelet[172]: E1230 14:08:11.789270     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:08:16 kind-worker2 kubelet[172]: E1230 14:08:16.791412     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:08:21 kind-worker2 kubelet[172]: E1230 14:08:21.793500     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:08:26 kind-worker2 kubelet[172]: E1230 14:08:26.795102     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:08:31 kind-worker2 kubelet[172]: E1230 14:08:31.796369     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:08:36 kind-worker2 kubelet[172]: E1230 14:08:36.799449     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:08:41 kind-worker2 kubelet[172]: E1230 14:08:41.781324     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:08:46 kind-worker2 kubelet[172]: E1230 14:08:46.783230     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:08:51 kind-worker2 kubelet[172]: E1230 14:08:51.784235     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:08:56 kind-worker2 kubelet[172]: E1230 14:08:56.785893     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:09:01 kind-worker2 kubelet[172]: W1230 14:09:01.549600     172 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Dec 30 14:09:01 kind-worker2 kubelet[172]: E1230 14:09:01.787861     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:09:06 kind-worker2 kubelet[172]: E1230 14:09:06.790684     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:09:11 kind-worker2 kubelet[172]: E1230 14:09:11.772254     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:09:16 kind-worker2 kubelet[172]: E1230 14:09:16.773332     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:09:21 kind-worker2 kubelet[172]: E1230 14:09:21.775481     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:09:26 kind-worker2 kubelet[172]: E1230 14:09:26.777102     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:09:31 kind-worker2 kubelet[172]: E1230 14:09:31.779376     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:09:36 kind-worker2 kubelet[172]: E1230 14:09:36.781826     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:09:41 kind-worker2 kubelet[172]: E1230 14:09:41.761648     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:09:46 kind-worker2 kubelet[172]: E1230 14:09:46.763234     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:09:51 kind-worker2 kubelet[172]: E1230 14:09:51.764778     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:09:56 kind-worker2 kubelet[172]: E1230 14:09:56.766914     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:10:01 kind-worker2 kubelet[172]: E1230 14:10:01.770235     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:10:06 kind-worker2 kubelet[172]: E1230 14:10:06.772360     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:10:11 kind-worker2 kubelet[172]: E1230 14:10:11.754669     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:10:16 kind-worker2 kubelet[172]: E1230 14:10:16.757267     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:10:21 kind-worker2 kubelet[172]: E1230 14:10:21.759845     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:10:26 kind-worker2 kubelet[172]: E1230 14:10:26.761964     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:10:31 kind-worker2 kubelet[172]: E1230 14:10:31.764269     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:10:36 kind-worker2 kubelet[172]: E1230 14:10:36.765983     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:10:41 kind-worker2 kubelet[172]: E1230 14:10:41.747146     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:10:46 kind-worker2 kubelet[172]: E1230 14:10:46.749929     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:10:51 kind-worker2 kubelet[172]: E1230 14:10:51.751582     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:10:56 kind-worker2 kubelet[172]: E1230 14:10:56.752642     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:11:01 kind-worker2 kubelet[172]: E1230 14:11:01.754449     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:11:06 kind-worker2 kubelet[172]: E1230 14:11:06.755574     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:11:11 kind-worker2 kubelet[172]: E1230 14:11:11.737200     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:11:16 kind-worker2 kubelet[172]: E1230 14:11:16.738511     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:11:21 kind-worker2 kubelet[172]: E1230 14:11:21.740031     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:11:26 kind-worker2 kubelet[172]: E1230 14:11:26.741158     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:11:31 kind-worker2 kubelet[172]: E1230 14:11:31.742604     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:11:36 kind-worker2 kubelet[172]: E1230 14:11:36.744386     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:11:41 kind-worker2 kubelet[172]: E1230 14:11:41.725407     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:11:46 kind-worker2 kubelet[172]: E1230 14:11:46.727063     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:11:51 kind-worker2 kubelet[172]: E1230 14:11:51.729253     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:11:56 kind-worker2 kubelet[172]: E1230 14:11:56.731137     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:12:01 kind-worker2 kubelet[172]: E1230 14:12:01.733532     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:12:06 kind-worker2 kubelet[172]: E1230 14:12:06.735426     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:12:11 kind-worker2 kubelet[172]: E1230 14:12:11.716211     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:12:16 kind-worker2 kubelet[172]: E1230 14:12:16.717753     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:12:21 kind-worker2 kubelet[172]: E1230 14:12:21.720126     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:12:26 kind-worker2 kubelet[172]: E1230 14:12:26.723553     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:12:31 kind-worker2 kubelet[172]: E1230 14:12:31.724804     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:12:36 kind-worker2 kubelet[172]: E1230 14:12:36.726919     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:12:41 kind-worker2 kubelet[172]: E1230 14:12:41.706805     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:12:46 kind-worker2 kubelet[172]: E1230 14:12:46.708760     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:12:51 kind-worker2 kubelet[172]: E1230 14:12:51.711023     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:12:56 kind-worker2 kubelet[172]: E1230 14:12:56.712616     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:13:01 kind-worker2 kubelet[172]: E1230 14:13:01.715174     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:13:06 kind-worker2 kubelet[172]: E1230 14:13:06.717013     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:13:11 kind-worker2 kubelet[172]: E1230 14:13:11.698011     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:13:16 kind-worker2 kubelet[172]: E1230 14:13:16.700009     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:13:21 kind-worker2 kubelet[172]: E1230 14:13:21.702541     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:13:26 kind-worker2 kubelet[172]: E1230 14:13:26.704559     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:13:31 kind-worker2 kubelet[172]: E1230 14:13:31.705600     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:13:36 kind-worker2 kubelet[172]: E1230 14:13:36.708359     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:13:41 kind-worker2 kubelet[172]: E1230 14:13:41.690342     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:13:46 kind-worker2 kubelet[172]: E1230 14:13:46.691102     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:13:51 kind-worker2 kubelet[172]: E1230 14:13:51.692405     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:13:56 kind-worker2 kubelet[172]: E1230 14:13:56.693216     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:14:01 kind-worker2 kubelet[172]: W1230 14:14:01.343883     172 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Dec 30 14:14:01 kind-worker2 kubelet[172]: E1230 14:14:01.694145     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:14:06 kind-worker2 kubelet[172]: E1230 14:14:06.695635     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:14:11 kind-worker2 kubelet[172]: E1230 14:14:11.677126     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:14:16 kind-worker2 kubelet[172]: E1230 14:14:16.678411     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:14:21 kind-worker2 kubelet[172]: E1230 14:14:21.680089     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:14:26 kind-worker2 kubelet[172]: E1230 14:14:26.681803     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:14:31 kind-worker2 kubelet[172]: E1230 14:14:31.682923     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:14:36 kind-worker2 kubelet[172]: E1230 14:14:36.684155     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:14:41 kind-worker2 kubelet[172]: E1230 14:14:41.665164     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:14:46 kind-worker2 kubelet[172]: E1230 14:14:46.666703     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:14:51 kind-worker2 kubelet[172]: E1230 14:14:51.668603     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:14:56 kind-worker2 kubelet[172]: E1230 14:14:56.669864     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:15:01 kind-worker2 kubelet[172]: E1230 14:15:01.670935     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:15:06 kind-worker2 kubelet[172]: E1230 14:15:06.672771     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:15:11 kind-worker2 kubelet[172]: E1230 14:15:11.653875     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:15:16 kind-worker2 kubelet[172]: E1230 14:15:16.656938     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:15:21 kind-worker2 kubelet[172]: E1230 14:15:21.658474     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:15:26 kind-worker2 kubelet[172]: E1230 14:15:26.659238     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:15:31 kind-worker2 kubelet[172]: E1230 14:15:31.660708     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:15:36 kind-worker2 kubelet[172]: E1230 14:15:36.661799     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:15:41 kind-worker2 kubelet[172]: E1230 14:15:41.642706     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:15:46 kind-worker2 kubelet[172]: E1230 14:15:46.643669     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:15:51 kind-worker2 kubelet[172]: E1230 14:15:51.646121     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:15:56 kind-worker2 kubelet[172]: E1230 14:15:56.648112     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:16:01 kind-worker2 kubelet[172]: E1230 14:16:01.649892     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:16:06 kind-worker2 kubelet[172]: E1230 14:16:06.651926     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:16:11 kind-worker2 kubelet[172]: E1230 14:16:11.632580     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:16:16 kind-worker2 kubelet[172]: E1230 14:16:16.634650     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:16:21 kind-worker2 kubelet[172]: E1230 14:16:21.637167     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:16:26 kind-worker2 kubelet[172]: E1230 14:16:26.639598     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:16:31 kind-worker2 kubelet[172]: E1230 14:16:31.640996     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:16:36 kind-worker2 kubelet[172]: E1230 14:16:36.642437     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:16:41 kind-worker2 kubelet[172]: E1230 14:16:41.623200     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:16:46 kind-worker2 kubelet[172]: E1230 14:16:46.624468     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:16:51 kind-worker2 kubelet[172]: E1230 14:16:51.625802     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:16:56 kind-worker2 kubelet[172]: E1230 14:16:56.628209     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:17:01 kind-worker2 kubelet[172]: E1230 14:17:01.629074     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:17:06 kind-worker2 kubelet[172]: E1230 14:17:06.631603     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:17:11 kind-worker2 kubelet[172]: E1230 14:17:11.613671     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:17:16 kind-worker2 kubelet[172]: E1230 14:17:16.615255     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:17:21 kind-worker2 kubelet[172]: E1230 14:17:21.617654     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:17:26 kind-worker2 kubelet[172]: E1230 14:17:26.619585     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:17:31 kind-worker2 kubelet[172]: E1230 14:17:31.622324     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:17:36 kind-worker2 kubelet[172]: E1230 14:17:36.624480     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:17:41 kind-worker2 kubelet[172]: E1230 14:17:41.607351     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:17:46 kind-worker2 kubelet[172]: E1230 14:17:46.608378     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:17:51 kind-worker2 kubelet[172]: E1230 14:17:51.611008     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:17:56 kind-worker2 kubelet[172]: E1230 14:17:56.612534     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:18:01 kind-worker2 kubelet[172]: E1230 14:18:01.614967     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:18:06 kind-worker2 kubelet[172]: E1230 14:18:06.616692     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:18:11 kind-worker2 kubelet[172]: E1230 14:18:11.597465     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:18:16 kind-worker2 kubelet[172]: E1230 14:18:16.598983     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:18:21 kind-worker2 kubelet[172]: E1230 14:18:21.600763     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:18:26 kind-worker2 kubelet[172]: E1230 14:18:26.603301     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:18:31 kind-worker2 kubelet[172]: E1230 14:18:31.604726     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:18:36 kind-worker2 kubelet[172]: E1230 14:18:36.606544     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:18:41 kind-worker2 kubelet[172]: E1230 14:18:41.588116     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:18:46 kind-worker2 kubelet[172]: E1230 14:18:46.590183     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:18:51 kind-worker2 kubelet[172]: E1230 14:18:51.591716     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:18:56 kind-worker2 kubelet[172]: E1230 14:18:56.593221     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:19:01 kind-worker2 kubelet[172]: W1230 14:19:01.134555     172 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Dec 30 14:19:01 kind-worker2 kubelet[172]: E1230 14:19:01.595208     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:19:06 kind-worker2 kubelet[172]: E1230 14:19:06.597054     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:19:11 kind-worker2 kubelet[172]: E1230 14:19:11.579023     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:19:16 kind-worker2 kubelet[172]: E1230 14:19:16.581350     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:19:21 kind-worker2 kubelet[172]: E1230 14:19:21.582649     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:19:26 kind-worker2 kubelet[172]: E1230 14:19:26.585611     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:19:31 kind-worker2 kubelet[172]: E1230 14:19:31.588602     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:19:36 kind-worker2 kubelet[172]: E1230 14:19:36.590340     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:19:41 kind-worker2 kubelet[172]: E1230 14:19:41.571783     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:19:46 kind-worker2 kubelet[172]: E1230 14:19:46.574158     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:19:51 kind-worker2 kubelet[172]: E1230 14:19:51.576767     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:19:56 kind-worker2 kubelet[172]: E1230 14:19:56.578758     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:20:01 kind-worker2 kubelet[172]: E1230 14:20:01.580425     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:20:06 kind-worker2 kubelet[172]: E1230 14:20:06.582587     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:20:11 kind-worker2 kubelet[172]: E1230 14:20:11.564300     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:20:16 kind-worker2 kubelet[172]: E1230 14:20:16.565289     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:20:21 kind-worker2 kubelet[172]: E1230 14:20:21.567063     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:20:26 kind-worker2 kubelet[172]: E1230 14:20:26.569410     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:20:31 kind-worker2 kubelet[172]: E1230 14:20:31.570622     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:20:36 kind-worker2 kubelet[172]: E1230 14:20:36.572246     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:20:41 kind-worker2 kubelet[172]: E1230 14:20:41.553727     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:20:46 kind-worker2 kubelet[172]: E1230 14:20:46.556085     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:20:51 kind-worker2 kubelet[172]: E1230 14:20:51.557583     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:20:56 kind-worker2 kubelet[172]: E1230 14:20:56.559767     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:21:01 kind-worker2 kubelet[172]: E1230 14:21:01.562167     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:21:06 kind-worker2 kubelet[172]: E1230 14:21:06.564115     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:21:11 kind-worker2 kubelet[172]: E1230 14:21:11.545630     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:21:16 kind-worker2 kubelet[172]: E1230 14:21:16.547589     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:21:21 kind-worker2 kubelet[172]: E1230 14:21:21.549084     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:21:26 kind-worker2 kubelet[172]: E1230 14:21:26.551941     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:21:31 kind-worker2 kubelet[172]: E1230 14:21:31.557628     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:21:36 kind-worker2 kubelet[172]: E1230 14:21:36.559239     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:21:41 kind-worker2 kubelet[172]: E1230 14:21:41.535048     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:21:46 kind-worker2 kubelet[172]: E1230 14:21:46.537005     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:21:51 kind-worker2 kubelet[172]: E1230 14:21:51.538591     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:21:56 kind-worker2 kubelet[172]: E1230 14:21:56.539625     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:22:01 kind-worker2 kubelet[172]: E1230 14:22:01.541446     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:22:06 kind-worker2 kubelet[172]: E1230 14:22:06.543351     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:22:11 kind-worker2 kubelet[172]: E1230 14:22:11.507165     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:22:16 kind-worker2 kubelet[172]: E1230 14:22:16.509054     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:22:21 kind-worker2 kubelet[172]: E1230 14:22:21.510313     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:22:26 kind-worker2 kubelet[172]: E1230 14:22:26.511665     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:22:31 kind-worker2 kubelet[172]: E1230 14:22:31.513676     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:22:36 kind-worker2 kubelet[172]: E1230 14:22:36.515568     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:22:41 kind-worker2 kubelet[172]: E1230 14:22:41.494647     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:22:46 kind-worker2 kubelet[172]: E1230 14:22:46.496414     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:22:51 kind-worker2 kubelet[172]: E1230 14:22:51.498892     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:22:56 kind-worker2 kubelet[172]: E1230 14:22:56.500798     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:23:01 kind-worker2 kubelet[172]: E1230 14:23:01.502749     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:23:06 kind-worker2 kubelet[172]: E1230 14:23:06.504147     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:23:11 kind-worker2 kubelet[172]: E1230 14:23:11.484050     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:23:16 kind-worker2 kubelet[172]: E1230 14:23:16.485704     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:23:21 kind-worker2 kubelet[172]: E1230 14:23:21.486920     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:23:26 kind-worker2 kubelet[172]: E1230 14:23:26.487829     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:23:31 kind-worker2 kubelet[172]: E1230 14:23:31.490589     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:23:36 kind-worker2 kubelet[172]: E1230 14:23:36.491884     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:23:41 kind-worker2 kubelet[172]: E1230 14:23:41.471948     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:23:46 kind-worker2 kubelet[172]: E1230 14:23:46.473024     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:23:51 kind-worker2 kubelet[172]: E1230 14:23:51.475070     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:23:56 kind-worker2 kubelet[172]: E1230 14:23:56.477042     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:24:00 kind-worker2 kubelet[172]: W1230 14:24:00.901208     172 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Dec 30 14:24:01 kind-worker2 kubelet[172]: E1230 14:24:01.478276     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:24:06 kind-worker2 kubelet[172]: E1230 14:24:06.480588     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:24:11 kind-worker2 kubelet[172]: E1230 14:24:11.460876     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:24:16 kind-worker2 kubelet[172]: E1230 14:24:16.462043     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:24:21 kind-worker2 kubelet[172]: E1230 14:24:21.464265     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:24:26 kind-worker2 kubelet[172]: E1230 14:24:26.466485     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:24:31 kind-worker2 kubelet[172]: E1230 14:24:31.467224     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:24:36 kind-worker2 kubelet[172]: E1230 14:24:36.468302     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:24:41 kind-worker2 kubelet[172]: E1230 14:24:41.449490     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:24:46 kind-worker2 kubelet[172]: E1230 14:24:46.451341     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:24:51 kind-worker2 kubelet[172]: E1230 14:24:51.452758     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:24:56 kind-worker2 kubelet[172]: E1230 14:24:56.454544     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:25:01 kind-worker2 kubelet[172]: E1230 14:25:01.457493     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:25:06 kind-worker2 kubelet[172]: E1230 14:25:06.459779     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:25:11 kind-worker2 kubelet[172]: E1230 14:25:11.440859     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:25:16 kind-worker2 kubelet[172]: E1230 14:25:16.443663     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:25:21 kind-worker2 kubelet[172]: E1230 14:25:21.445432     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:25:26 kind-worker2 kubelet[172]: E1230 14:25:26.447499     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:25:31 kind-worker2 kubelet[172]: E1230 14:25:31.449694     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:25:36 kind-worker2 kubelet[172]: E1230 14:25:36.452758     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:25:41 kind-worker2 kubelet[172]: E1230 14:25:41.434068     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:25:46 kind-worker2 kubelet[172]: E1230 14:25:46.435272     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:25:51 kind-worker2 kubelet[172]: E1230 14:25:51.437698     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:25:56 kind-worker2 kubelet[172]: E1230 14:25:56.440321     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:26:01 kind-worker2 kubelet[172]: E1230 14:26:01.442867     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:26:06 kind-worker2 kubelet[172]: E1230 14:26:06.444845     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:26:11 kind-worker2 kubelet[172]: E1230 14:26:11.426886     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:26:16 kind-worker2 kubelet[172]: E1230 14:26:16.428762     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:26:21 kind-worker2 kubelet[172]: E1230 14:26:21.430932     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:26:26 kind-worker2 kubelet[172]: E1230 14:26:26.433093     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:26:31 kind-worker2 kubelet[172]: E1230 14:26:31.434450     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:26:36 kind-worker2 kubelet[172]: E1230 14:26:36.435570     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:26:41 kind-worker2 kubelet[172]: E1230 14:26:41.416492     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:26:46 kind-worker2 kubelet[172]: E1230 14:26:46.418127     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:26:51 kind-worker2 kubelet[172]: E1230 14:26:51.419667     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:26:56 kind-worker2 kubelet[172]: E1230 14:26:56.422473     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:27:01 kind-worker2 kubelet[172]: E1230 14:27:01.424318     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:27:06 kind-worker2 kubelet[172]: E1230 14:27:06.426274     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:27:11 kind-worker2 kubelet[172]: E1230 14:27:11.407045     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:27:16 kind-worker2 kubelet[172]: E1230 14:27:16.409176     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:27:21 kind-worker2 kubelet[172]: E1230 14:27:21.411791     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:27:26 kind-worker2 kubelet[172]: E1230 14:27:26.414018     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:27:31 kind-worker2 kubelet[172]: E1230 14:27:31.416477     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:27:36 kind-worker2 kubelet[172]: E1230 14:27:36.418462     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:27:41 kind-worker2 kubelet[172]: E1230 14:27:41.400202     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:27:46 kind-worker2 kubelet[172]: E1230 14:27:46.401537     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:27:51 kind-worker2 kubelet[172]: E1230 14:27:51.403594     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:27:56 kind-worker2 kubelet[172]: E1230 14:27:56.405393     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:28:01 kind-worker2 kubelet[172]: E1230 14:28:01.407482     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:28:06 kind-worker2 kubelet[172]: E1230 14:28:06.408526     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:28:11 kind-worker2 kubelet[172]: E1230 14:28:11.389346     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:28:14 kind-worker2 kubelet[172]: I1230 14:28:14.040023     172 topology_manager.go:187] "Topology Admit Handler"
Dec 30 14:28:14 kind-worker2 kubelet[172]: I1230 14:28:14.079968     172 topology_manager.go:187] "Topology Admit Handler"
Dec 30 14:28:14 kind-worker2 kubelet[172]: I1230 14:28:14.164739     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni-path\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-cni-path\") pod \"cilium-vtwd8\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:28:14 kind-worker2 kubelet[172]: I1230 14:28:14.164800     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"hubble-tls\" (UniqueName: \"kubernetes.io/projected/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-hubble-tls\") pod \"cilium-vtwd8\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:28:14 kind-worker2 kubelet[172]: I1230 14:28:14.164819     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-cni-netd\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-etc-cni-netd\") pod \"cilium-vtwd8\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:28:14 kind-worker2 kubelet[172]: I1230 14:28:14.164834     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-lib-modules\") pod \"cilium-vtwd8\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:28:14 kind-worker2 kubelet[172]: I1230 14:28:14.164854     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-xtables-lock\") pod \"cilium-vtwd8\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:28:14 kind-worker2 kubelet[172]: I1230 14:28:14.164869     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"host-proc\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-host-proc\") pod \"cilium-vtwd8\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:28:14 kind-worker2 kubelet[172]: I1230 14:28:14.164887     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cilium-config-path\" (UniqueName: \"kubernetes.io/configmap/98e858b8-f3f5-4339-b0a1-e82bb8abcba7-cilium-config-path\") pod \"cilium-operator-58f7855696-vxkx4\" (UID: \"98e858b8-f3f5-4339-b0a1-e82bb8abcba7\") "
Dec 30 14:28:14 kind-worker2 kubelet[172]: I1230 14:28:14.164904     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-dbdq2\" (UniqueName: \"kubernetes.io/projected/98e858b8-f3f5-4339-b0a1-e82bb8abcba7-kube-api-access-dbdq2\") pod \"cilium-operator-58f7855696-vxkx4\" (UID: \"98e858b8-f3f5-4339-b0a1-e82bb8abcba7\") "
Dec 30 14:28:14 kind-worker2 kubelet[172]: I1230 14:28:14.164957     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cilium-run\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-cilium-run\") pod \"cilium-vtwd8\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:28:14 kind-worker2 kubelet[172]: I1230 14:28:14.164985     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"bpf-maps\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-bpf-maps\") pod \"cilium-vtwd8\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:28:14 kind-worker2 kubelet[172]: I1230 14:28:14.165003     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"clustermesh-secrets\" (UniqueName: \"kubernetes.io/secret/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-clustermesh-secrets\") pod \"cilium-vtwd8\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:28:14 kind-worker2 kubelet[172]: I1230 14:28:14.165026     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cilium-config-path\" (UniqueName: \"kubernetes.io/configmap/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-cilium-config-path\") pod \"cilium-vtwd8\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:28:14 kind-worker2 kubelet[172]: I1230 14:28:14.165042     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-vp4fm\" (UniqueName: \"kubernetes.io/projected/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-kube-api-access-vp4fm\") pod \"cilium-vtwd8\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:28:16 kind-worker2 kubelet[172]: E1230 14:28:16.391350     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:28:21 kind-worker2 kubelet[172]: E1230 14:28:21.392219     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:28:26 kind-worker2 kubelet[172]: E1230 14:28:26.393891     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:28:31 kind-worker2 kubelet[172]: E1230 14:28:31.395333     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:28:36 kind-worker2 kubelet[172]: E1230 14:28:36.396394     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:28:41 kind-worker2 kubelet[172]: E1230 14:28:41.376586     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:28:46 kind-worker2 kubelet[172]: E1230 14:28:46.378185     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:28:51 kind-worker2 kubelet[172]: E1230 14:28:51.379866     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:28:56 kind-worker2 kubelet[172]: E1230 14:28:56.380880     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:29:00 kind-worker2 kubelet[172]: W1230 14:29:00.690217     172 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Dec 30 14:29:01 kind-worker2 kubelet[172]: E1230 14:29:01.382536     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:29:06 kind-worker2 kubelet[172]: E1230 14:29:06.384016     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:29:11 kind-worker2 kubelet[172]: E1230 14:29:11.363646     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:29:16 kind-worker2 kubelet[172]: E1230 14:29:16.364968     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:29:21 kind-worker2 kubelet[172]: E1230 14:29:21.366218     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:29:26 kind-worker2 kubelet[172]: E1230 14:29:26.368087     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:29:31 kind-worker2 kubelet[172]: E1230 14:29:31.369422     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:29:36 kind-worker2 kubelet[172]: E1230 14:29:36.375398     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:29:41 kind-worker2 kubelet[172]: E1230 14:29:41.356209     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:29:46 kind-worker2 kubelet[172]: E1230 14:29:46.358949     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:29:51 kind-worker2 kubelet[172]: E1230 14:29:51.364933     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.417533     172 scope.go:111] "RemoveContainer" containerID="350a078d5c49cee518602af8ef1fd1fed8f17858f0c564141ed35e2a7f82ed05"
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.423045     172 scope.go:111] "RemoveContainer" containerID="d485eea691425b46edecff14e439d97993a560532804b073207a6acb24413158"
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.427497     172 scope.go:111] "RemoveContainer" containerID="44fc98b3e2adc944f6f3574467446d9de0285e42f6a9c1323191feb76d034763"
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.434306     172 scope.go:111] "RemoveContainer" containerID="350a078d5c49cee518602af8ef1fd1fed8f17858f0c564141ed35e2a7f82ed05"
Dec 30 14:31:38 kind-worker2 kubelet[172]: E1230 14:31:38.434705     172 remote_runtime.go:334] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"350a078d5c49cee518602af8ef1fd1fed8f17858f0c564141ed35e2a7f82ed05\": not found" containerID="350a078d5c49cee518602af8ef1fd1fed8f17858f0c564141ed35e2a7f82ed05"
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.434763     172 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:350a078d5c49cee518602af8ef1fd1fed8f17858f0c564141ed35e2a7f82ed05} err="failed to get container status \"350a078d5c49cee518602af8ef1fd1fed8f17858f0c564141ed35e2a7f82ed05\": rpc error: code = NotFound desc = an error occurred when try to find container \"350a078d5c49cee518602af8ef1fd1fed8f17858f0c564141ed35e2a7f82ed05\": not found"
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.434778     172 scope.go:111] "RemoveContainer" containerID="d485eea691425b46edecff14e439d97993a560532804b073207a6acb24413158"
Dec 30 14:31:38 kind-worker2 kubelet[172]: E1230 14:31:38.435269     172 remote_runtime.go:334] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"d485eea691425b46edecff14e439d97993a560532804b073207a6acb24413158\": not found" containerID="d485eea691425b46edecff14e439d97993a560532804b073207a6acb24413158"
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.435331     172 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:d485eea691425b46edecff14e439d97993a560532804b073207a6acb24413158} err="failed to get container status \"d485eea691425b46edecff14e439d97993a560532804b073207a6acb24413158\": rpc error: code = NotFound desc = an error occurred when try to find container \"d485eea691425b46edecff14e439d97993a560532804b073207a6acb24413158\": not found"
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.435349     172 scope.go:111] "RemoveContainer" containerID="44fc98b3e2adc944f6f3574467446d9de0285e42f6a9c1323191feb76d034763"
Dec 30 14:31:38 kind-worker2 kubelet[172]: E1230 14:31:38.436061     172 remote_runtime.go:334] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"44fc98b3e2adc944f6f3574467446d9de0285e42f6a9c1323191feb76d034763\": not found" containerID="44fc98b3e2adc944f6f3574467446d9de0285e42f6a9c1323191feb76d034763"
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.436268     172 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:44fc98b3e2adc944f6f3574467446d9de0285e42f6a9c1323191feb76d034763} err="failed to get container status \"44fc98b3e2adc944f6f3574467446d9de0285e42f6a9c1323191feb76d034763\": rpc error: code = NotFound desc = an error occurred when try to find container \"44fc98b3e2adc944f6f3574467446d9de0285e42f6a9c1323191feb76d034763\": not found"
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.481114     172 reconciler.go:196] "operationExecutor.UnmountVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-lib-modules\") pod \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.481397     172 operation_generator.go:829] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-lib-modules" (OuterVolumeSpecName: "lib-modules") pod "6cdf10f3-8142-4ba6-a9b6-d13714c60d39" (UID: "6cdf10f3-8142-4ba6-a9b6-d13714c60d39"). InnerVolumeSpecName "lib-modules". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.481431     172 reconciler.go:196] "operationExecutor.UnmountVolume started for volume \"host-proc\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-host-proc\") pod \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.481513     172 reconciler.go:196] "operationExecutor.UnmountVolume started for volume \"cilium-config-path\" (UniqueName: \"kubernetes.io/configmap/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-cilium-config-path\") pod \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.481536     172 reconciler.go:196] "operationExecutor.UnmountVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-xtables-lock\") pod \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.481558     172 reconciler.go:196] "operationExecutor.UnmountVolume started for volume \"kube-api-access-vp4fm\" (UniqueName: \"kubernetes.io/projected/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-kube-api-access-vp4fm\") pod \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.481575     172 reconciler.go:196] "operationExecutor.UnmountVolume started for volume \"etc-cni-netd\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-etc-cni-netd\") pod \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.481630     172 operation_generator.go:829] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-xtables-lock" (OuterVolumeSpecName: "xtables-lock") pod "6cdf10f3-8142-4ba6-a9b6-d13714c60d39" (UID: "6cdf10f3-8142-4ba6-a9b6-d13714c60d39"). InnerVolumeSpecName "xtables-lock". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.481668     172 operation_generator.go:829] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-etc-cni-netd" (OuterVolumeSpecName: "etc-cni-netd") pod "6cdf10f3-8142-4ba6-a9b6-d13714c60d39" (UID: "6cdf10f3-8142-4ba6-a9b6-d13714c60d39"). InnerVolumeSpecName "etc-cni-netd". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.481731     172 operation_generator.go:829] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-host-proc" (OuterVolumeSpecName: "host-proc") pod "6cdf10f3-8142-4ba6-a9b6-d13714c60d39" (UID: "6cdf10f3-8142-4ba6-a9b6-d13714c60d39"). InnerVolumeSpecName "host-proc". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.482038     172 reconciler.go:196] "operationExecutor.UnmountVolume started for volume \"clustermesh-secrets\" (UniqueName: \"kubernetes.io/secret/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-clustermesh-secrets\") pod \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.482155     172 reconciler.go:196] "operationExecutor.UnmountVolume started for volume \"hubble-tls\" (UniqueName: \"kubernetes.io/projected/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-hubble-tls\") pod \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.482177     172 reconciler.go:196] "operationExecutor.UnmountVolume started for volume \"cni-path\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-cni-path\") pod \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.482194     172 reconciler.go:196] "operationExecutor.UnmountVolume started for volume \"bpf-maps\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-bpf-maps\") pod \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.482211     172 reconciler.go:196] "operationExecutor.UnmountVolume started for volume \"cilium-run\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-cilium-run\") pod \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\" (UID: \"6cdf10f3-8142-4ba6-a9b6-d13714c60d39\") "
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.482241     172 reconciler.go:319] "Volume detached for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-lib-modules\") on node \"kind-worker2\" DevicePath \"\""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.482253     172 reconciler.go:319] "Volume detached for volume \"host-proc\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-host-proc\") on node \"kind-worker2\" DevicePath \"\""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.482263     172 reconciler.go:319] "Volume detached for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-xtables-lock\") on node \"kind-worker2\" DevicePath \"\""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.482272     172 reconciler.go:319] "Volume detached for volume \"etc-cni-netd\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-etc-cni-netd\") on node \"kind-worker2\" DevicePath \"\""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.482295     172 operation_generator.go:829] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-cilium-run" (OuterVolumeSpecName: "cilium-run") pod "6cdf10f3-8142-4ba6-a9b6-d13714c60d39" (UID: "6cdf10f3-8142-4ba6-a9b6-d13714c60d39"). InnerVolumeSpecName "cilium-run". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.482317     172 operation_generator.go:829] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-cni-path" (OuterVolumeSpecName: "cni-path") pod "6cdf10f3-8142-4ba6-a9b6-d13714c60d39" (UID: "6cdf10f3-8142-4ba6-a9b6-d13714c60d39"). InnerVolumeSpecName "cni-path". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.482335     172 operation_generator.go:829] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-bpf-maps" (OuterVolumeSpecName: "bpf-maps") pod "6cdf10f3-8142-4ba6-a9b6-d13714c60d39" (UID: "6cdf10f3-8142-4ba6-a9b6-d13714c60d39"). InnerVolumeSpecName "bpf-maps". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Dec 30 14:31:38 kind-worker2 kubelet[172]: W1230 14:31:38.482428     172 empty_dir.go:520] Warning: Failed to clear quota on /var/lib/kubelet/pods/6cdf10f3-8142-4ba6-a9b6-d13714c60d39/volumes/kubernetes.io~configmap/cilium-config-path: clearQuota called, but quotas disabled
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.483980     172 operation_generator.go:829] UnmountVolume.TearDown succeeded for volume "kubernetes.io/configmap/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-cilium-config-path" (OuterVolumeSpecName: "cilium-config-path") pod "6cdf10f3-8142-4ba6-a9b6-d13714c60d39" (UID: "6cdf10f3-8142-4ba6-a9b6-d13714c60d39"). InnerVolumeSpecName "cilium-config-path". PluginName "kubernetes.io/configmap", VolumeGidValue ""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.487379     172 operation_generator.go:829] UnmountVolume.TearDown succeeded for volume "kubernetes.io/secret/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-clustermesh-secrets" (OuterVolumeSpecName: "clustermesh-secrets") pod "6cdf10f3-8142-4ba6-a9b6-d13714c60d39" (UID: "6cdf10f3-8142-4ba6-a9b6-d13714c60d39"). InnerVolumeSpecName "clustermesh-secrets". PluginName "kubernetes.io/secret", VolumeGidValue ""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.487406     172 operation_generator.go:829] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-kube-api-access-vp4fm" (OuterVolumeSpecName: "kube-api-access-vp4fm") pod "6cdf10f3-8142-4ba6-a9b6-d13714c60d39" (UID: "6cdf10f3-8142-4ba6-a9b6-d13714c60d39"). InnerVolumeSpecName "kube-api-access-vp4fm". PluginName "kubernetes.io/projected", VolumeGidValue ""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.487554     172 operation_generator.go:829] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-hubble-tls" (OuterVolumeSpecName: "hubble-tls") pod "6cdf10f3-8142-4ba6-a9b6-d13714c60d39" (UID: "6cdf10f3-8142-4ba6-a9b6-d13714c60d39"). InnerVolumeSpecName "hubble-tls". PluginName "kubernetes.io/projected", VolumeGidValue ""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.583195     172 reconciler.go:319] "Volume detached for volume \"kube-api-access-vp4fm\" (UniqueName: \"kubernetes.io/projected/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-kube-api-access-vp4fm\") on node \"kind-worker2\" DevicePath \"\""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.583281     172 reconciler.go:319] "Volume detached for volume \"clustermesh-secrets\" (UniqueName: \"kubernetes.io/secret/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-clustermesh-secrets\") on node \"kind-worker2\" DevicePath \"\""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.583304     172 reconciler.go:319] "Volume detached for volume \"cni-path\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-cni-path\") on node \"kind-worker2\" DevicePath \"\""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.583317     172 reconciler.go:319] "Volume detached for volume \"bpf-maps\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-bpf-maps\") on node \"kind-worker2\" DevicePath \"\""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.583332     172 reconciler.go:319] "Volume detached for volume \"cilium-run\" (UniqueName: \"kubernetes.io/host-path/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-cilium-run\") on node \"kind-worker2\" DevicePath \"\""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.583345     172 reconciler.go:319] "Volume detached for volume \"hubble-tls\" (UniqueName: \"kubernetes.io/projected/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-hubble-tls\") on node \"kind-worker2\" DevicePath \"\""
Dec 30 14:31:38 kind-worker2 kubelet[172]: I1230 14:31:38.583358     172 reconciler.go:319] "Volume detached for volume \"cilium-config-path\" (UniqueName: \"kubernetes.io/configmap/6cdf10f3-8142-4ba6-a9b6-d13714c60d39-cilium-config-path\") on node \"kind-worker2\" DevicePath \"\""
Dec 30 14:31:38 kind-worker2 kubelet[172]: E1230 14:31:38.661612     172 kuberuntime_container.go:691] "Kill container failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"350a078d5c49cee518602af8ef1fd1fed8f17858f0c564141ed35e2a7f82ed05\": not found" pod="kube-system/cilium-vtwd8" podUID=6cdf10f3-8142-4ba6-a9b6-d13714c60d39 containerName="cilium-agent" containerID={Type:containerd ID:350a078d5c49cee518602af8ef1fd1fed8f17858f0c564141ed35e2a7f82ed05}
Dec 30 14:31:38 kind-worker2 kubelet[172]: E1230 14:31:38.662192     172 kubelet_pods.go:1288] "Failed killing the pod" err="failed to \"KillContainer\" for \"cilium-agent\" with KillContainerError: \"rpc error: code = NotFound desc = an error occurred when try to find container \\\"350a078d5c49cee518602af8ef1fd1fed8f17858f0c564141ed35e2a7f82ed05\\\": not found\"" podName="cilium-vtwd8"
Dec 30 14:31:39 kind-worker2 kubelet[172]: I1230 14:31:39.427366     172 topology_manager.go:187] "Topology Admit Handler"
Dec 30 14:31:39 kind-worker2 kubelet[172]: I1230 14:31:39.569765     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/cdadd77d-9f75-49c6-9050-b4c954e6b6f5-xtables-lock\") pod \"cilium-tkq6w\" (UID: \"cdadd77d-9f75-49c6-9050-b4c954e6b6f5\") "
Dec 30 14:31:39 kind-worker2 kubelet[172]: I1230 14:31:39.569931     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/cdadd77d-9f75-49c6-9050-b4c954e6b6f5-lib-modules\") pod \"cilium-tkq6w\" (UID: \"cdadd77d-9f75-49c6-9050-b4c954e6b6f5\") "
Dec 30 14:31:39 kind-worker2 kubelet[172]: I1230 14:31:39.569984     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"clustermesh-secrets\" (UniqueName: \"kubernetes.io/secret/cdadd77d-9f75-49c6-9050-b4c954e6b6f5-clustermesh-secrets\") pod \"cilium-tkq6w\" (UID: \"cdadd77d-9f75-49c6-9050-b4c954e6b6f5\") "
Dec 30 14:31:39 kind-worker2 kubelet[172]: I1230 14:31:39.570064     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"hubble-tls\" (UniqueName: \"kubernetes.io/projected/cdadd77d-9f75-49c6-9050-b4c954e6b6f5-hubble-tls\") pod \"cilium-tkq6w\" (UID: \"cdadd77d-9f75-49c6-9050-b4c954e6b6f5\") "
Dec 30 14:31:39 kind-worker2 kubelet[172]: I1230 14:31:39.570108     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"host-proc\" (UniqueName: \"kubernetes.io/host-path/cdadd77d-9f75-49c6-9050-b4c954e6b6f5-host-proc\") pod \"cilium-tkq6w\" (UID: \"cdadd77d-9f75-49c6-9050-b4c954e6b6f5\") "
Dec 30 14:31:39 kind-worker2 kubelet[172]: I1230 14:31:39.570259     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-2bs82\" (UniqueName: \"kubernetes.io/projected/cdadd77d-9f75-49c6-9050-b4c954e6b6f5-kube-api-access-2bs82\") pod \"cilium-tkq6w\" (UID: \"cdadd77d-9f75-49c6-9050-b4c954e6b6f5\") "
Dec 30 14:31:39 kind-worker2 kubelet[172]: I1230 14:31:39.570469     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cilium-run\" (UniqueName: \"kubernetes.io/host-path/cdadd77d-9f75-49c6-9050-b4c954e6b6f5-cilium-run\") pod \"cilium-tkq6w\" (UID: \"cdadd77d-9f75-49c6-9050-b4c954e6b6f5\") "
Dec 30 14:31:39 kind-worker2 kubelet[172]: I1230 14:31:39.570519     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"bpf-maps\" (UniqueName: \"kubernetes.io/host-path/cdadd77d-9f75-49c6-9050-b4c954e6b6f5-bpf-maps\") pod \"cilium-tkq6w\" (UID: \"cdadd77d-9f75-49c6-9050-b4c954e6b6f5\") "
Dec 30 14:31:39 kind-worker2 kubelet[172]: I1230 14:31:39.570554     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni-path\" (UniqueName: \"kubernetes.io/host-path/cdadd77d-9f75-49c6-9050-b4c954e6b6f5-cni-path\") pod \"cilium-tkq6w\" (UID: \"cdadd77d-9f75-49c6-9050-b4c954e6b6f5\") "
Dec 30 14:31:39 kind-worker2 kubelet[172]: I1230 14:31:39.570666     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-cni-netd\" (UniqueName: \"kubernetes.io/host-path/cdadd77d-9f75-49c6-9050-b4c954e6b6f5-etc-cni-netd\") pod \"cilium-tkq6w\" (UID: \"cdadd77d-9f75-49c6-9050-b4c954e6b6f5\") "
Dec 30 14:31:39 kind-worker2 kubelet[172]: I1230 14:31:39.570845     172 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cilium-config-path\" (UniqueName: \"kubernetes.io/configmap/cdadd77d-9f75-49c6-9050-b4c954e6b6f5-cilium-config-path\") pod \"cilium-tkq6w\" (UID: \"cdadd77d-9f75-49c6-9050-b4c954e6b6f5\") "
Dec 30 14:31:41 kind-worker2 kubelet[172]: E1230 14:31:41.322777     172 kubelet.go:2211] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Dec 30 14:31:41 kind-worker2 kubelet[172]: W1230 14:31:41.972493     172 manager.go:1176] Failed to process watch event {EventType:0 Name:/kubelet/kubepods/burstable/podcdadd77d-9f75-49c6-9050-b4c954e6b6f5/a9b853a198286580ac0db2b4cd1a1154da417525da5b17647c8de6ae480f3772 WatchSource:0}: task a9b853a198286580ac0db2b4cd1a1154da417525da5b17647c8de6ae480f3772 not found: not found
Dec 30 14:31:43 kind-worker2 kubelet[172]: I1230 14:31:43.678482     172 setters.go:577] "Node became not ready" node="kind-worker2" condition={Type:Ready Status:False LastHeartbeatTime:2021-12-30 14:31:43.678395126 +0000 UTC m=+1970.396127710 LastTransitionTime:2021-12-30 14:31:43.678395126 +0000 UTC m=+1970.396127710 Reason:KubeletNotReady Message:container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized}
Dec 30 14:31:54 kind-worker2 kubelet[172]: I1230 14:31:54.445960     172 scope.go:111] "RemoveContainer" containerID="d5118850aa2db6f3883c17975378371c58aee7645f51af60e635e951138cd92b"
Dec 30 14:32:03 kind-worker2 kubelet[172]: E1230 14:32:03.689265     172 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": context deadline exceeded
Dec 30 14:32:03 kind-worker2 kubelet[172]: E1230 14:32:03.690361     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?resourceVersion=0&timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
Dec 30 14:32:13 kind-worker2 kubelet[172]: E1230 14:32:13.668679     172 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": net/http: request canceled (Client.Timeout exceeded while awaiting headers)
Dec 30 14:32:13 kind-worker2 kubelet[172]: E1230 14:32:13.669357     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58edbeb8497f3", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Pulled", Message:"Container image \"quay.io/cilium/operator-generic-service-mesh:v1.11.0-beta.1\" already present on machine", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": read tcp 172.18.0.2:42298->172.18.0.4:6443: use of closed network connection'(may retry after sleeping)
Dec 30 14:32:14 kind-worker2 kubelet[172]: E1230 14:32:14.670966     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": context deadline exceeded"
Dec 30 14:32:17 kind-worker2 kubelet[172]: E1230 14:32:17.026421     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?allowWatchBookmarks=true&fieldSelector=metadata.name%3Dkind-worker2&resourceVersion=3809&timeout=6m57s&timeoutSeconds=417&watch=true": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:17 kind-worker2 kubelet[172]: E1230 14:32:17.026432     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:17 kind-worker2 kubelet[172]: E1230 14:32:17.026626     172 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?allowWatchBookmarks=true&fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=3132&timeout=8m3s&timeoutSeconds=483&watch=true": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:17 kind-worker2 kubelet[172]: E1230 14:32:17.026731     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?allowWatchBookmarks=true&resourceVersion=3309&timeout=5m19s&timeoutSeconds=319&watch=true": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:17 kind-worker2 kubelet[172]: E1230 14:32:17.026757     172 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:17 kind-worker2 kubelet[172]: E1230 14:32:17.026856     172 reflector.go:138] object-"kube-system"/"hubble-server-certs": Failed to watch *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?allowWatchBookmarks=true&fieldSelector=metadata.name%3Dhubble-server-certs&resourceVersion=3126&timeout=7m22s&timeoutSeconds=442&watch=true": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:17 kind-worker2 kubelet[172]: E1230 14:32:17.026922     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?allowWatchBookmarks=true&resourceVersion=3478&timeout=8m38s&timeoutSeconds=518&watch=true": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:17 kind-worker2 kubelet[172]: I1230 14:32:17.026453     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:17 kind-worker2 kubelet[172]: E1230 14:32:17.027076     172 reflector.go:138] object-"kube-system"/"cilium-clustermesh": Failed to watch *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?allowWatchBookmarks=true&fieldSelector=metadata.name%3Dcilium-clustermesh&resourceVersion=3126&timeout=9m52s&timeoutSeconds=592&watch=true": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:17 kind-worker2 kubelet[172]: E1230 14:32:17.026969     172 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?allowWatchBookmarks=true&fieldSelector=spec.nodeName%3Dkind-worker2&resourceVersion=3796&timeoutSeconds=589&watch=true": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:17 kind-worker2 kubelet[172]: E1230 14:32:17.027219     172 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?allowWatchBookmarks=true&fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=3132&timeout=6m17s&timeoutSeconds=377&watch=true": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:17 kind-worker2 kubelet[172]: E1230 14:32:17.027135     172 reflector.go:138] object-"kube-system"/"cilium-config": Failed to watch *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?allowWatchBookmarks=true&fieldSelector=metadata.name%3Dcilium-config&resourceVersion=3714&timeout=9m18s&timeoutSeconds=558&watch=true": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:17 kind-worker2 kubelet[172]: E1230 14:32:17.028031     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?allowWatchBookmarks=true&resourceVersion=3244&timeout=5m32s&timeoutSeconds=332&watch=true": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:20 kind-worker2 kubelet[172]: E1230 14:32:20.097909     172 reflector.go:138] object-"kube-system"/"cilium-clustermesh": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dcilium-clustermesh&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:20 kind-worker2 kubelet[172]: E1230 14:32:20.097916     172 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:20 kind-worker2 kubelet[172]: E1230 14:32:20.098014     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:20 kind-worker2 kubelet[172]: I1230 14:32:20.098545     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:23 kind-worker2 kubelet[172]: E1230 14:32:23.170268     172 reflector.go:138] object-"kube-system"/"hubble-server-certs": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dhubble-server-certs&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:23 kind-worker2 kubelet[172]: E1230 14:32:23.170480     172 reflector.go:138] object-"kube-system"/"cilium-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcilium-config&resourceVersion=3714": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:23 kind-worker2 kubelet[172]: E1230 14:32:23.170654     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=3478": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:23 kind-worker2 kubelet[172]: E1230 14:32:23.170655     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=3244": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:23 kind-worker2 kubelet[172]: E1230 14:32:23.170704     172 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-worker2&resourceVersion=3796": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:23 kind-worker2 kubelet[172]: E1230 14:32:23.170725     172 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:23 kind-worker2 kubelet[172]: E1230 14:32:23.170739     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=3309": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:23 kind-worker2 kubelet[172]: E1230 14:32:23.170793     172 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:23 kind-worker2 kubelet[172]: E1230 14:32:23.170883     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-worker2&resourceVersion=3809": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:23 kind-worker2 kubelet[172]: E1230 14:32:23.489898     172 reflector.go:138] object-"kube-system"/"cilium-clustermesh": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dcilium-clustermesh&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:23 kind-worker2 kubelet[172]: E1230 14:32:23.489977     172 controller.go:187] failed to update lease, error: Put "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:23 kind-worker2 kubelet[172]: I1230 14:32:23.490092     172 controller.go:114] failed to update lease using latest lease, fallback to ensure lease, err: failed 5 attempts to update lease
Dec 30 14:32:23 kind-worker2 kubelet[172]: I1230 14:32:23.490232     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:23 kind-worker2 kubelet[172]: E1230 14:32:23.490407     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:23 kind-worker2 kubelet[172]: E1230 14:32:23.490430     172 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Dec 30 14:32:23 kind-worker2 kubelet[172]: E1230 14:32:23.490537     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58edbeb8497f3", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Pulled", Message:"Container image \"quay.io/cilium/operator-generic-service-mesh:v1.11.0-beta.1\" already present on machine", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:32:26 kind-worker2 kubelet[172]: E1230 14:32:26.562888     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=3478": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:26 kind-worker2 kubelet[172]: E1230 14:32:26.562885     172 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:26 kind-worker2 kubelet[172]: E1230 14:32:26.562885     172 reflector.go:138] object-"kube-system"/"hubble-server-certs": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dhubble-server-certs&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:26 kind-worker2 kubelet[172]: E1230 14:32:26.562917     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=3309": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:26 kind-worker2 kubelet[172]: E1230 14:32:26.562968     172 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-worker2&resourceVersion=3796": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:26 kind-worker2 kubelet[172]: E1230 14:32:26.562992     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-worker2&resourceVersion=3809": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:26 kind-worker2 kubelet[172]: E1230 14:32:26.563043     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=3244": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:26 kind-worker2 kubelet[172]: E1230 14:32:26.563047     172 controller.go:144] failed to ensure lease exists, will retry in 200ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:26 kind-worker2 kubelet[172]: I1230 14:32:26.563070     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:26 kind-worker2 kubelet[172]: E1230 14:32:26.563129     172 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:26 kind-worker2 kubelet[172]: E1230 14:32:26.563592     172 reflector.go:138] object-"kube-system"/"cilium-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcilium-config&resourceVersion=3714": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:32 kind-worker2 kubelet[172]: E1230 14:32:32.387551     172 reflector.go:138] object-"kube-system"/"cilium-clustermesh": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dcilium-clustermesh&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:32 kind-worker2 kubelet[172]: E1230 14:32:32.388038     172 controller.go:144] failed to ensure lease exists, will retry in 400ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:32 kind-worker2 kubelet[172]: I1230 14:32:32.388217     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:33 kind-worker2 kubelet[172]: E1230 14:32:33.025541     172 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:33 kind-worker2 kubelet[172]: E1230 14:32:33.025541     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=3309": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:33 kind-worker2 kubelet[172]: E1230 14:32:33.025585     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=3244": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:33 kind-worker2 kubelet[172]: E1230 14:32:33.025588     172 reflector.go:138] object-"kube-system"/"hubble-server-certs": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dhubble-server-certs&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:33 kind-worker2 kubelet[172]: E1230 14:32:33.025641     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=3478": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:35 kind-worker2 kubelet[172]: I1230 14:32:35.458520     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:35 kind-worker2 kubelet[172]: E1230 14:32:35.458809     172 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-worker2&resourceVersion=3796": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:35 kind-worker2 kubelet[172]: E1230 14:32:35.459209     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-worker2&resourceVersion=3809": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:36 kind-worker2 kubelet[172]: E1230 14:32:36.161635     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?resourceVersion=0&timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:36 kind-worker2 kubelet[172]: E1230 14:32:36.161665     172 reflector.go:138] object-"kube-system"/"cilium-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcilium-config&resourceVersion=3714": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:36 kind-worker2 kubelet[172]: E1230 14:32:36.161748     172 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:36 kind-worker2 kubelet[172]: E1230 14:32:36.161795     172 controller.go:144] failed to ensure lease exists, will retry in 800ms, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:36 kind-worker2 kubelet[172]: E1230 14:32:36.161635     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58edbeb8497f3", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Pulled", Message:"Container image \"quay.io/cilium/operator-generic-service-mesh:v1.11.0-beta.1\" already present on machine", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:32:38 kind-worker2 kubelet[172]: I1230 14:32:38.530270     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:39 kind-worker2 kubelet[172]: E1230 14:32:39.213355     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:39 kind-worker2 kubelet[172]: E1230 14:32:39.213380     172 controller.go:144] failed to ensure lease exists, will retry in 1.6s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:42 kind-worker2 kubelet[172]: E1230 14:32:42.604913     172 controller.go:144] failed to ensure lease exists, will retry in 3.2s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:42 kind-worker2 kubelet[172]: E1230 14:32:42.605061     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:42 kind-worker2 kubelet[172]: I1230 14:32:42.605066     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:42 kind-worker2 kubelet[172]: E1230 14:32:42.605371     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=3309": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:42 kind-worker2 kubelet[172]: E1230 14:32:42.605866     172 reflector.go:138] object-"kube-system"/"hubble-server-certs": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dhubble-server-certs&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:42 kind-worker2 kubelet[172]: E1230 14:32:42.606002     172 reflector.go:138] object-"kube-system"/"cilium-clustermesh": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dcilium-clustermesh&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:44 kind-worker2 kubelet[172]: E1230 14:32:44.652697     172 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:44 kind-worker2 kubelet[172]: E1230 14:32:44.652934     172 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-worker2&resourceVersion=3796": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:45 kind-worker2 kubelet[172]: E1230 14:32:45.676728     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:45 kind-worker2 kubelet[172]: I1230 14:32:45.676738     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:45 kind-worker2 kubelet[172]: E1230 14:32:45.677098     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=3244": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:48 kind-worker2 kubelet[172]: E1230 14:32:48.877058     172 controller.go:144] failed to ensure lease exists, will retry in 6.4s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:48 kind-worker2 kubelet[172]: E1230 14:32:48.877087     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-worker2&resourceVersion=3809": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:48 kind-worker2 kubelet[172]: E1230 14:32:48.877026     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58edbeb8497f3", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Pulled", Message:"Container image \"quay.io/cilium/operator-generic-service-mesh:v1.11.0-beta.1\" already present on machine", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:32:48 kind-worker2 kubelet[172]: E1230 14:32:48.877147     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=3478": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:48 kind-worker2 kubelet[172]: E1230 14:32:48.877206     172 reflector.go:138] object-"kube-system"/"cilium-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcilium-config&resourceVersion=3714": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:48 kind-worker2 kubelet[172]: E1230 14:32:48.877110     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:48 kind-worker2 kubelet[172]: E1230 14:32:48.877327     172 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Dec 30 14:32:51 kind-worker2 kubelet[172]: I1230 14:32:51.950152     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:51 kind-worker2 kubelet[172]: E1230 14:32:51.950227     172 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:55 kind-worker2 kubelet[172]: I1230 14:32:55.340818     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:32:57 kind-worker2 kubelet[172]: I1230 14:32:57.560575     172 scope.go:111] "RemoveContainer" containerID="d5118850aa2db6f3883c17975378371c58aee7645f51af60e635e951138cd92b"
Dec 30 14:32:57 kind-worker2 kubelet[172]: I1230 14:32:57.560832     172 scope.go:111] "RemoveContainer" containerID="abe68c61b394038ae68b9da8ab5d9e3081a551b633baf1b7292d8002ca7edadc"
Dec 30 14:32:57 kind-worker2 kubelet[172]: E1230 14:32:57.561061     172 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cilium-operator\" with CrashLoopBackOff: \"back-off 10s restarting failed container=cilium-operator pod=cilium-operator-58f7855696-vxkx4_kube-system(98e858b8-f3f5-4339-b0a1-e82bb8abcba7)\"" pod="kube-system/cilium-operator-58f7855696-vxkx4" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7
Dec 30 14:32:58 kind-worker2 kubelet[172]: E1230 14:32:58.413428     172 reflector.go:138] object-"kube-system"/"hubble-server-certs": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dhubble-server-certs&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:32:58 kind-worker2 kubelet[172]: E1230 14:32:58.413397     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:00 kind-worker2 kubelet[172]: I1230 14:33:00.012753     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:02 kind-worker2 kubelet[172]: E1230 14:33:02.252880     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?resourceVersion=0&timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:02 kind-worker2 kubelet[172]: E1230 14:33:02.252871     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58edbeb8497f3", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Pulled", Message:"Container image \"quay.io/cilium/operator-generic-service-mesh:v1.11.0-beta.1\" already present on machine", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:33:03 kind-worker2 kubelet[172]: I1230 14:33:03.086036     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:05 kind-worker2 kubelet[172]: E1230 14:33:05.324707     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:05 kind-worker2 kubelet[172]: E1230 14:33:05.324724     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-worker2&resourceVersion=3809": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:06 kind-worker2 kubelet[172]: E1230 14:33:06.157542     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=3309": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:06 kind-worker2 kubelet[172]: E1230 14:33:06.157550     172 reflector.go:138] object-"kube-system"/"cilium-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcilium-config&resourceVersion=3714": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:06 kind-worker2 kubelet[172]: I1230 14:33:06.157632     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:08 kind-worker2 kubelet[172]: E1230 14:33:08.718052     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:08 kind-worker2 kubelet[172]: E1230 14:33:08.718380     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:09 kind-worker2 kubelet[172]: E1230 14:33:09.208860     172 reflector.go:138] object-"kube-system"/"cilium-clustermesh": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dcilium-clustermesh&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:09 kind-worker2 kubelet[172]: E1230 14:33:09.208924     172 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-worker2&resourceVersion=3796": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:09 kind-worker2 kubelet[172]: E1230 14:33:09.208912     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=3478": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:09 kind-worker2 kubelet[172]: E1230 14:33:09.209147     172 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:09 kind-worker2 kubelet[172]: E1230 14:33:09.208918     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=3244": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:10 kind-worker2 kubelet[172]: I1230 14:33:10.572501     172 scope.go:111] "RemoveContainer" containerID="abe68c61b394038ae68b9da8ab5d9e3081a551b633baf1b7292d8002ca7edadc"
Dec 30 14:33:11 kind-worker2 kubelet[172]: E1230 14:33:11.768250     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:12 kind-worker2 kubelet[172]: I1230 14:33:12.280191     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:12 kind-worker2 kubelet[172]: E1230 14:33:12.280560     172 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:15 kind-worker2 kubelet[172]: E1230 14:33:15.160222     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:15 kind-worker2 kubelet[172]: E1230 14:33:15.161396     172 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Dec 30 14:33:15 kind-worker2 kubelet[172]: E1230 14:33:15.160158     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58edbeb8497f3", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Pulled", Message:"Container image \"quay.io/cilium/operator-generic-service-mesh:v1.11.0-beta.1\" already present on machine", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:33:15 kind-worker2 kubelet[172]: I1230 14:33:15.351781     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:18 kind-worker2 kubelet[172]: E1230 14:33:18.424586     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:18 kind-worker2 kubelet[172]: I1230 14:33:18.424609     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:21 kind-worker2 kubelet[172]: I1230 14:33:21.815944     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:24 kind-worker2 kubelet[172]: I1230 14:33:24.887589     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:28 kind-worker2 kubelet[172]: E1230 14:33:28.279703     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:28 kind-worker2 kubelet[172]: I1230 14:33:28.279717     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:28 kind-worker2 kubelet[172]: E1230 14:33:28.279724     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?resourceVersion=0&timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:28 kind-worker2 kubelet[172]: E1230 14:33:28.279784     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58edbeb8497f3", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Pulled", Message:"Container image \"quay.io/cilium/operator-generic-service-mesh:v1.11.0-beta.1\" already present on machine", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:33:31 kind-worker2 kubelet[172]: I1230 14:33:31.351733     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:31 kind-worker2 kubelet[172]: E1230 14:33:31.351778     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:34 kind-worker2 kubelet[172]: I1230 14:33:34.743860     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:34 kind-worker2 kubelet[172]: E1230 14:33:34.743904     172 reflector.go:138] object-"kube-system"/"hubble-server-certs": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dhubble-server-certs&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:34 kind-worker2 kubelet[172]: E1230 14:33:34.743963     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:37 kind-worker2 kubelet[172]: E1230 14:33:37.816001     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:37 kind-worker2 kubelet[172]: E1230 14:33:37.816044     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:37 kind-worker2 kubelet[172]: E1230 14:33:37.816054     172 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-worker2&resourceVersion=3796": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:41 kind-worker2 kubelet[172]: I1230 14:33:41.188088     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:41 kind-worker2 kubelet[172]: E1230 14:33:41.188313     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58edbeb8497f3", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Pulled", Message:"Container image \"quay.io/cilium/operator-generic-service-mesh:v1.11.0-beta.1\" already present on machine", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:33:41 kind-worker2 kubelet[172]: E1230 14:33:41.188517     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:41 kind-worker2 kubelet[172]: E1230 14:33:41.188543     172 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Dec 30 14:33:42 kind-worker2 kubelet[172]: E1230 14:33:42.979442     172 reflector.go:138] object-"kube-system"/"cilium-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcilium-config&resourceVersion=3714": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:44 kind-worker2 kubelet[172]: I1230 14:33:44.258840     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:44 kind-worker2 kubelet[172]: E1230 14:33:44.258887     172 reflector.go:138] object-"kube-system"/"cilium-clustermesh": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dcilium-clustermesh&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:47 kind-worker2 kubelet[172]: E1230 14:33:47.651133     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:47 kind-worker2 kubelet[172]: I1230 14:33:47.651166     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:49 kind-worker2 kubelet[172]: E1230 14:33:49.123698     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=3244": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:50 kind-worker2 kubelet[172]: E1230 14:33:50.723750     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=3478": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:52 kind-worker2 kubelet[172]: E1230 14:33:52.195450     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=3309": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:53 kind-worker2 kubelet[172]: I1230 14:33:53.922760     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:53 kind-worker2 kubelet[172]: E1230 14:33:53.923125     172 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:53 kind-worker2 kubelet[172]: E1230 14:33:53.923113     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58edbeb8497f3", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Pulled", Message:"Container image \"quay.io/cilium/operator-generic-service-mesh:v1.11.0-beta.1\" already present on machine", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:33:53 kind-worker2 kubelet[172]: E1230 14:33:53.923218     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?resourceVersion=0&timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:56 kind-worker2 kubelet[172]: E1230 14:33:56.994874     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:33:56 kind-worker2 kubelet[172]: I1230 14:33:56.994905     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:56 kind-worker2 kubelet[172]: E1230 14:33:56.994927     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:33:58 kind-worker2 kubelet[172]: E1230 14:33:58.339649     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-worker2&resourceVersion=3809": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:00 kind-worker2 kubelet[172]: E1230 14:34:00.387189     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:00 kind-worker2 kubelet[172]: W1230 14:34:00.483451     172 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Dec 30 14:34:04 kind-worker2 kubelet[172]: E1230 14:34:04.484256     172 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:04 kind-worker2 kubelet[172]: I1230 14:34:04.484407     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:04 kind-worker2 kubelet[172]: E1230 14:34:04.484448     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:07 kind-worker2 kubelet[172]: E1230 14:34:07.300202     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:07 kind-worker2 kubelet[172]: E1230 14:34:07.300227     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58edbeb8497f3", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Pulled", Message:"Container image \"quay.io/cilium/operator-generic-service-mesh:v1.11.0-beta.1\" already present on machine", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:34:07 kind-worker2 kubelet[172]: E1230 14:34:07.555464     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:07 kind-worker2 kubelet[172]: E1230 14:34:07.555790     172 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Dec 30 14:34:07 kind-worker2 kubelet[172]: I1230 14:34:07.555491     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:13 kind-worker2 kubelet[172]: I1230 14:34:13.678548     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:16 kind-worker2 kubelet[172]: E1230 14:34:16.750151     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:16 kind-worker2 kubelet[172]: I1230 14:34:16.750209     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:16 kind-worker2 kubelet[172]: E1230 14:34:16.750277     172 reflector.go:138] object-"kube-system"/"hubble-server-certs": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dhubble-server-certs&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:17 kind-worker2 kubelet[172]: I1230 14:34:17.676374     172 scope.go:111] "RemoveContainer" containerID="abe68c61b394038ae68b9da8ab5d9e3081a551b633baf1b7292d8002ca7edadc"
Dec 30 14:34:17 kind-worker2 kubelet[172]: I1230 14:34:17.676632     172 scope.go:111] "RemoveContainer" containerID="e478913bb0da85f334ad5b5c7a444d40271ede5938bb4382c55dbcca7073d334"
Dec 30 14:34:17 kind-worker2 kubelet[172]: E1230 14:34:17.676829     172 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cilium-operator\" with CrashLoopBackOff: \"back-off 20s restarting failed container=cilium-operator pod=cilium-operator-58f7855696-vxkx4_kube-system(98e858b8-f3f5-4339-b0a1-e82bb8abcba7)\"" pod="kube-system/cilium-operator-58f7855696-vxkx4" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7
Dec 30 14:34:20 kind-worker2 kubelet[172]: E1230 14:34:20.654568     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?resourceVersion=0&timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:20 kind-worker2 kubelet[172]: E1230 14:34:20.654581     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58edbeb8497f3", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Pulled", Message:"Container image \"quay.io/cilium/operator-generic-service-mesh:v1.11.0-beta.1\" already present on machine", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:34:20 kind-worker2 kubelet[172]: I1230 14:34:20.654638     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:20 kind-worker2 kubelet[172]: E1230 14:34:20.655435     172 reflector.go:138] object-"kube-system"/"cilium-clustermesh": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dcilium-clustermesh&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:23 kind-worker2 kubelet[172]: E1230 14:34:23.725635     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:23 kind-worker2 kubelet[172]: I1230 14:34:23.725637     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:27 kind-worker2 kubelet[172]: E1230 14:34:27.118932     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=3478": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:27 kind-worker2 kubelet[172]: E1230 14:34:27.118927     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:27 kind-worker2 kubelet[172]: E1230 14:34:27.118935     172 reflector.go:138] object-"kube-system"/"cilium-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcilium-config&resourceVersion=3714": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:27 kind-worker2 kubelet[172]: E1230 14:34:27.118982     172 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:27 kind-worker2 kubelet[172]: I1230 14:34:27.119223     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:27 kind-worker2 kubelet[172]: E1230 14:34:27.119387     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:30 kind-worker2 kubelet[172]: E1230 14:34:30.189388     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:32 kind-worker2 kubelet[172]: I1230 14:34:32.530230     172 scope.go:111] "RemoveContainer" containerID="e478913bb0da85f334ad5b5c7a444d40271ede5938bb4382c55dbcca7073d334"
Dec 30 14:34:32 kind-worker2 kubelet[172]: E1230 14:34:32.530481     172 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cilium-operator\" with CrashLoopBackOff: \"back-off 20s restarting failed container=cilium-operator pod=cilium-operator-58f7855696-vxkx4_kube-system(98e858b8-f3f5-4339-b0a1-e82bb8abcba7)\"" pod="kube-system/cilium-operator-58f7855696-vxkx4" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7
Dec 30 14:34:33 kind-worker2 kubelet[172]: I1230 14:34:33.583297     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:33 kind-worker2 kubelet[172]: E1230 14:34:33.583280     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58edbeb8497f3", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Pulled", Message:"Container image \"quay.io/cilium/operator-generic-service-mesh:v1.11.0-beta.1\" already present on machine", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Post "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:34:33 kind-worker2 kubelet[172]: E1230 14:34:33.583511     172 event.go:218] Unable to write event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58edbeb8497f3", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Pulled", Message:"Container image \"quay.io/cilium/operator-generic-service-mesh:v1.11.0-beta.1\" already present on machine", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969aa093f3, ext:1981164463847, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}' (retry limit exceeded!)
Dec 30 14:34:33 kind-worker2 kubelet[172]: E1230 14:34:33.583606     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:33 kind-worker2 kubelet[172]: E1230 14:34:33.583636     172 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Dec 30 14:34:33 kind-worker2 kubelet[172]: E1230 14:34:33.583404     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-worker2&resourceVersion=3809": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:36 kind-worker2 kubelet[172]: E1230 14:34:36.654827     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:36 kind-worker2 kubelet[172]: E1230 14:34:36.654861     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=3309": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:36 kind-worker2 kubelet[172]: I1230 14:34:36.655024     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:36 kind-worker2 kubelet[172]: E1230 14:34:36.654955     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58ead8db74cae", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"3201", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Created", Message:"Created container cilium-operator", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63776471315, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969c0d66ca, ext:1981188372930, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/cilium-operator-58f7855696-vxkx4.16c58ead8db74cae": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:34:36 kind-worker2 kubelet[172]: E1230 14:34:36.655351     172 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-worker2&resourceVersion=3796": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:40 kind-worker2 kubelet[172]: I1230 14:34:40.024793     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:41 kind-worker2 kubelet[172]: E1230 14:34:41.304976     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=3244": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:43 kind-worker2 kubelet[172]: I1230 14:34:43.097472     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:46 kind-worker2 kubelet[172]: E1230 14:34:46.489103     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?resourceVersion=0&timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:46 kind-worker2 kubelet[172]: E1230 14:34:46.489082     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:46 kind-worker2 kubelet[172]: I1230 14:34:46.489104     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:47 kind-worker2 kubelet[172]: E1230 14:34:47.449498     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58ead8db74cae", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"3201", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Created", Message:"Created container cilium-operator", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63776471315, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969c0d66ca, ext:1981188372930, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/cilium-operator-58f7855696-vxkx4.16c58ead8db74cae": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:34:47 kind-worker2 kubelet[172]: E1230 14:34:47.450005     172 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:47 kind-worker2 kubelet[172]: I1230 14:34:47.508532     172 scope.go:111] "RemoveContainer" containerID="e478913bb0da85f334ad5b5c7a444d40271ede5938bb4382c55dbcca7073d334"
Dec 30 14:34:49 kind-worker2 kubelet[172]: E1230 14:34:49.560926     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:50 kind-worker2 kubelet[172]: I1230 14:34:50.521311     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:52 kind-worker2 kubelet[172]: E1230 14:34:52.953828     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:53 kind-worker2 kubelet[172]: I1230 14:34:53.593339     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:56 kind-worker2 kubelet[172]: E1230 14:34:56.025393     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:56 kind-worker2 kubelet[172]: E1230 14:34:56.025426     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:56 kind-worker2 kubelet[172]: I1230 14:34:56.665785     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:56 kind-worker2 kubelet[172]: E1230 14:34:56.666159     172 reflector.go:138] object-"kube-system"/"hubble-server-certs": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dhubble-server-certs&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:34:59 kind-worker2 kubelet[172]: E1230 14:34:59.417031     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:34:59 kind-worker2 kubelet[172]: E1230 14:34:59.417101     172 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Dec 30 14:34:59 kind-worker2 kubelet[172]: E1230 14:34:59.737370     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58ead8db74cae", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"3201", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Created", Message:"Created container cilium-operator", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63776471315, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969c0d66ca, ext:1981188372930, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/cilium-operator-58f7855696-vxkx4.16c58ead8db74cae": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:35:02 kind-worker2 kubelet[172]: I1230 14:35:02.809691     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:05 kind-worker2 kubelet[172]: I1230 14:35:05.881119     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:05 kind-worker2 kubelet[172]: E1230 14:35:05.881180     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:05 kind-worker2 kubelet[172]: E1230 14:35:05.881260     172 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:08 kind-worker2 kubelet[172]: E1230 14:35:08.931973     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=3478": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:08 kind-worker2 kubelet[172]: E1230 14:35:08.932163     172 reflector.go:138] object-"kube-system"/"cilium-clustermesh": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dcilium-clustermesh&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:12 kind-worker2 kubelet[172]: E1230 14:35:12.772165     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58ead8db74cae", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"3201", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Created", Message:"Created container cilium-operator", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63776471315, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969c0d66ca, ext:1981188372930, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/cilium-operator-58f7855696-vxkx4.16c58ead8db74cae": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:35:12 kind-worker2 kubelet[172]: E1230 14:35:12.772291     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?resourceVersion=0&timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:12 kind-worker2 kubelet[172]: I1230 14:35:12.772387     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:15 kind-worker2 kubelet[172]: E1230 14:35:15.843764     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:15 kind-worker2 kubelet[172]: I1230 14:35:15.843765     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:15 kind-worker2 kubelet[172]: E1230 14:35:15.844574     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:19 kind-worker2 kubelet[172]: E1230 14:35:19.235795     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:19 kind-worker2 kubelet[172]: E1230 14:35:19.235816     172 reflector.go:138] object-"kube-system"/"cilium-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcilium-config&resourceVersion=3714": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:22 kind-worker2 kubelet[172]: E1230 14:35:22.307660     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:22 kind-worker2 kubelet[172]: I1230 14:35:22.307678     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:22 kind-worker2 kubelet[172]: E1230 14:35:22.308253     172 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-worker2&resourceVersion=3796": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:24 kind-worker2 kubelet[172]: E1230 14:35:24.291484     172 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:25 kind-worker2 kubelet[172]: E1230 14:35:25.699667     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:25 kind-worker2 kubelet[172]: E1230 14:35:25.699656     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58ead8db74cae", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"3201", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Created", Message:"Created container cilium-operator", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63776471315, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969c0d66ca, ext:1981188372930, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/cilium-operator-58f7855696-vxkx4.16c58ead8db74cae": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:35:25 kind-worker2 kubelet[172]: E1230 14:35:25.699741     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:25 kind-worker2 kubelet[172]: E1230 14:35:25.699803     172 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Dec 30 14:35:25 kind-worker2 kubelet[172]: I1230 14:35:25.700443     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:33 kind-worker2 kubelet[172]: E1230 14:35:33.891627     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:33 kind-worker2 kubelet[172]: E1230 14:35:33.891739     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-worker2&resourceVersion=3809": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:33 kind-worker2 kubelet[172]: I1230 14:35:33.891834     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:36 kind-worker2 kubelet[172]: E1230 14:35:36.964671     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?resourceVersion=0&timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:36 kind-worker2 kubelet[172]: E1230 14:35:36.964702     172 reflector.go:138] object-"kube-system"/"hubble-server-certs": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dhubble-server-certs&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:36 kind-worker2 kubelet[172]: E1230 14:35:36.964776     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58ead8db74cae", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"3201", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Created", Message:"Created container cilium-operator", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63776471315, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969c0d66ca, ext:1981188372930, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/cilium-operator-58f7855696-vxkx4.16c58ead8db74cae": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:35:36 kind-worker2 kubelet[172]: E1230 14:35:36.964701     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=3309": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:36 kind-worker2 kubelet[172]: I1230 14:35:36.964707     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:36 kind-worker2 kubelet[172]: E1230 14:35:36.965299     172 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:40 kind-worker2 kubelet[172]: E1230 14:35:40.334738     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:43 kind-worker2 kubelet[172]: E1230 14:35:43.406371     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:43 kind-worker2 kubelet[172]: E1230 14:35:43.406388     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:43 kind-worker2 kubelet[172]: I1230 14:35:43.406471     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:43 kind-worker2 kubelet[172]: E1230 14:35:43.406401     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=3244": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:46 kind-worker2 kubelet[172]: E1230 14:35:46.799405     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:46 kind-worker2 kubelet[172]: I1230 14:35:46.799839     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:49 kind-worker2 kubelet[172]: E1230 14:35:49.870473     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58ead8db74cae", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"3201", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Created", Message:"Created container cilium-operator", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63776471315, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969c0d66ca, ext:1981188372930, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/cilium-operator-58f7855696-vxkx4.16c58ead8db74cae": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:35:49 kind-worker2 kubelet[172]: E1230 14:35:49.870597     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:49 kind-worker2 kubelet[172]: E1230 14:35:49.870708     172 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Dec 30 14:35:52 kind-worker2 kubelet[172]: I1230 14:35:52.872130     172 scope.go:111] "RemoveContainer" containerID="e478913bb0da85f334ad5b5c7a444d40271ede5938bb4382c55dbcca7073d334"
Dec 30 14:35:52 kind-worker2 kubelet[172]: I1230 14:35:52.872371     172 scope.go:111] "RemoveContainer" containerID="11c77cfbb5529f9529bb59cc26479e80b6b91d183293be4b53c48366ef317e54"
Dec 30 14:35:52 kind-worker2 kubelet[172]: E1230 14:35:52.872657     172 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cilium-operator\" with CrashLoopBackOff: \"back-off 40s restarting failed container=cilium-operator pod=cilium-operator-58f7855696-vxkx4_kube-system(98e858b8-f3f5-4339-b0a1-e82bb8abcba7)\"" pod="kube-system/cilium-operator-58f7855696-vxkx4" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7
Dec 30 14:35:53 kind-worker2 kubelet[172]: E1230 14:35:53.775137     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:53 kind-worker2 kubelet[172]: I1230 14:35:53.774931     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:35:55 kind-worker2 kubelet[172]: E1230 14:35:55.055548     172 reflector.go:138] object-"kube-system"/"cilium-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcilium-config&resourceVersion=3714": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:35:56 kind-worker2 kubelet[172]: I1230 14:35:56.846549     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:00 kind-worker2 kubelet[172]: I1230 14:36:00.238810     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:01 kind-worker2 kubelet[172]: E1230 14:36:01.198865     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?resourceVersion=0&timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:01 kind-worker2 kubelet[172]: E1230 14:36:01.198837     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58ead8db74cae", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"3201", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Created", Message:"Created container cilium-operator", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63776471315, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969c0d66ca, ext:1981188372930, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/cilium-operator-58f7855696-vxkx4.16c58ead8db74cae": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:36:03 kind-worker2 kubelet[172]: E1230 14:36:03.310853     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:03 kind-worker2 kubelet[172]: I1230 14:36:03.310902     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:04 kind-worker2 kubelet[172]: E1230 14:36:04.271067     172 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:04 kind-worker2 kubelet[172]: E1230 14:36:04.271125     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=3478": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:04 kind-worker2 kubelet[172]: E1230 14:36:04.271074     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:05 kind-worker2 kubelet[172]: I1230 14:36:05.466895     172 scope.go:111] "RemoveContainer" containerID="11c77cfbb5529f9529bb59cc26479e80b6b91d183293be4b53c48366ef317e54"
Dec 30 14:36:05 kind-worker2 kubelet[172]: E1230 14:36:05.467408     172 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cilium-operator\" with CrashLoopBackOff: \"back-off 40s restarting failed container=cilium-operator pod=cilium-operator-58f7855696-vxkx4_kube-system(98e858b8-f3f5-4339-b0a1-e82bb8abcba7)\"" pod="kube-system/cilium-operator-58f7855696-vxkx4" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7
Dec 30 14:36:06 kind-worker2 kubelet[172]: I1230 14:36:06.447335     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:06 kind-worker2 kubelet[172]: E1230 14:36:06.447632     172 reflector.go:138] object-"kube-system"/"cilium-clustermesh": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dcilium-clustermesh&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:07 kind-worker2 kubelet[172]: E1230 14:36:07.343275     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:09 kind-worker2 kubelet[172]: I1230 14:36:09.497892     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:10 kind-worker2 kubelet[172]: E1230 14:36:10.394825     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:13 kind-worker2 kubelet[172]: I1230 14:36:13.467033     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:13 kind-worker2 kubelet[172]: E1230 14:36:13.467978     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:13 kind-worker2 kubelet[172]: E1230 14:36:13.468103     172 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Dec 30 14:36:13 kind-worker2 kubelet[172]: E1230 14:36:13.468491     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:13 kind-worker2 kubelet[172]: E1230 14:36:13.468792     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58ead8db74cae", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"3201", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Created", Message:"Created container cilium-operator", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63776471315, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969c0d66ca, ext:1981188372930, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/cilium-operator-58f7855696-vxkx4.16c58ead8db74cae": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:36:16 kind-worker2 kubelet[172]: I1230 14:36:16.446797     172 scope.go:111] "RemoveContainer" containerID="11c77cfbb5529f9529bb59cc26479e80b6b91d183293be4b53c48366ef317e54"
Dec 30 14:36:16 kind-worker2 kubelet[172]: E1230 14:36:16.447937     172 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cilium-operator\" with CrashLoopBackOff: \"back-off 40s restarting failed container=cilium-operator pod=cilium-operator-58f7855696-vxkx4_kube-system(98e858b8-f3f5-4339-b0a1-e82bb8abcba7)\"" pod="kube-system/cilium-operator-58f7855696-vxkx4" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7
Dec 30 14:36:16 kind-worker2 kubelet[172]: I1230 14:36:16.539235     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:23 kind-worker2 kubelet[172]: E1230 14:36:23.641786     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:23 kind-worker2 kubelet[172]: I1230 14:36:23.641819     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:23 kind-worker2 kubelet[172]: E1230 14:36:23.641834     172 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:66: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://kind-control-plane:6443/api/v1/pods?fieldSelector=spec.nodeName%3Dkind-worker2&resourceVersion=3796": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:26 kind-worker2 kubelet[172]: E1230 14:36:26.714053     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?resourceVersion=0&timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:26 kind-worker2 kubelet[172]: E1230 14:36:26.714050     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58ead8db74cae", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"3201", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Created", Message:"Created container cilium-operator", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63776471315, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969c0d66ca, ext:1981188372930, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/cilium-operator-58f7855696-vxkx4.16c58ead8db74cae": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:36:26 kind-worker2 kubelet[172]: I1230 14:36:26.714055     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:26 kind-worker2 kubelet[172]: E1230 14:36:26.714075     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-worker2&resourceVersion=3809": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:28 kind-worker2 kubelet[172]: I1230 14:36:28.446953     172 scope.go:111] "RemoveContainer" containerID="11c77cfbb5529f9529bb59cc26479e80b6b91d183293be4b53c48366ef317e54"
Dec 30 14:36:28 kind-worker2 kubelet[172]: E1230 14:36:28.448178     172 pod_workers.go:190] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"cilium-operator\" with CrashLoopBackOff: \"back-off 40s restarting failed container=cilium-operator pod=cilium-operator-58f7855696-vxkx4_kube-system(98e858b8-f3f5-4339-b0a1-e82bb8abcba7)\"" pod="kube-system/cilium-operator-58f7855696-vxkx4" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7
Dec 30 14:36:29 kind-worker2 kubelet[172]: E1230 14:36:29.914391     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:29 kind-worker2 kubelet[172]: E1230 14:36:29.914604     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=3309": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:32 kind-worker2 kubelet[172]: E1230 14:36:32.986046     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:32 kind-worker2 kubelet[172]: E1230 14:36:32.986097     172 reflector.go:138] object-"kube-system"/"hubble-server-certs": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dhubble-server-certs&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:32 kind-worker2 kubelet[172]: I1230 14:36:32.986150     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:32 kind-worker2 kubelet[172]: E1230 14:36:32.986338     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:36 kind-worker2 kubelet[172]: E1230 14:36:36.249920     172 reflector.go:138] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-proxy&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:36 kind-worker2 kubelet[172]: I1230 14:36:36.250055     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:36 kind-worker2 kubelet[172]: E1230 14:36:36.250136     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:39 kind-worker2 kubelet[172]: E1230 14:36:39.300794     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=3244": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:39 kind-worker2 kubelet[172]: E1230 14:36:39.300738     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58ead8db74cae", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"3201", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Created", Message:"Created container cilium-operator", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63776471315, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969c0d66ca, ext:1981188372930, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/cilium-operator-58f7855696-vxkx4.16c58ead8db74cae": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:36:39 kind-worker2 kubelet[172]: E1230 14:36:39.300863     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:39 kind-worker2 kubelet[172]: E1230 14:36:39.301507     172 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Dec 30 14:36:40 kind-worker2 kubelet[172]: I1230 14:36:40.426014     172 scope.go:111] "RemoveContainer" containerID="11c77cfbb5529f9529bb59cc26479e80b6b91d183293be4b53c48366ef317e54"
Dec 30 14:36:43 kind-worker2 kubelet[172]: E1230 14:36:43.332966     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://kind-control-plane:6443/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=3478": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:43 kind-worker2 kubelet[172]: I1230 14:36:43.332969     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:43 kind-worker2 kubelet[172]: E1230 14:36:43.333010     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:46 kind-worker2 kubelet[172]: I1230 14:36:46.405800     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:46 kind-worker2 kubelet[172]: E1230 14:36:46.405856     172 reflector.go:138] object-"kube-system"/"cilium-clustermesh": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dcilium-clustermesh&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:49 kind-worker2 kubelet[172]: I1230 14:36:49.796617     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:50 kind-worker2 kubelet[172]: E1230 14:36:50.948865     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?resourceVersion=0&timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:50 kind-worker2 kubelet[172]: E1230 14:36:50.948826     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58ead8db74cae", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"3201", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Created", Message:"Created container cilium-operator", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63776471315, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969c0d66ca, ext:1981188372930, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/cilium-operator-58f7855696-vxkx4.16c58ead8db74cae": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:36:50 kind-worker2 kubelet[172]: E1230 14:36:50.948954     172 event.go:218] Unable to write event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58edbecf16aca", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Created", Message:"Created container cilium-operator", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969c0d66ca, ext:1981188372930, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e969c0d66ca, ext:1981188372930, loc:(*time.Location)(0x74aba00)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}' (retry limit exceeded!)
Dec 30 14:36:52 kind-worker2 kubelet[172]: E1230 14:36:52.869036     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:52 kind-worker2 kubelet[172]: I1230 14:36:52.869080     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:52 kind-worker2 kubelet[172]: E1230 14:36:52.869147     172 reflector.go:138] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dkube-root-ca.crt&resourceVersion=3132": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:36:54 kind-worker2 kubelet[172]: E1230 14:36:54.020862     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:54 kind-worker2 kubelet[172]: E1230 14:36:54.020863     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58ead917a3f4e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"3202", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Started", Message:"Started container cilium-operator", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63776471315, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e96a066a636, ext:1981261330731, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/cilium-operator-58f7855696-vxkx4.16c58ead917a3f4e": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:36:56 kind-worker2 kubelet[172]: I1230 14:36:56.260822     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:57 kind-worker2 kubelet[172]: E1230 14:36:57.092783     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:36:57 kind-worker2 kubelet[172]: E1230 14:36:57.092804     172 reflector.go:138] object-"kube-system"/"cilium-config": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dcilium-config&resourceVersion=3714": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:37:00 kind-worker2 kubelet[172]: E1230 14:37:00.165293     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:37:03 kind-worker2 kubelet[172]: E1230 14:37:03.237163     172 kubelet_node_status.go:470] "Error updating node status, will retry" err="error getting node \"kind-worker2\": Get \"https://kind-control-plane:6443/api/v1/nodes/kind-worker2?timeout=10s\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:37:03 kind-worker2 kubelet[172]: E1230 14:37:03.237277     172 kubelet_node_status.go:457] "Unable to update node status" err="update node status exceeds retry count"
Dec 30 14:37:03 kind-worker2 kubelet[172]: I1230 14:37:03.237136     172 status_manager.go:566] "Failed to get status for pod" podUID=98e858b8-f3f5-4339-b0a1-e82bb8abcba7 pod="kube-system/cilium-operator-58f7855696-vxkx4" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-operator-58f7855696-vxkx4\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:37:03 kind-worker2 kubelet[172]: E1230 14:37:03.237337     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:37:03 kind-worker2 kubelet[172]: E1230 14:37:03.237468     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://kind-control-plane:6443/api/v1/services?resourceVersion=3309": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:37:06 kind-worker2 kubelet[172]: I1230 14:37:06.308937     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:37:06 kind-worker2 kubelet[172]: E1230 14:37:06.308848     172 event.go:273] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"cilium-operator-58f7855696-vxkx4.16c58ead917a3f4e", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"3202", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"cilium-operator-58f7855696-vxkx4", UID:"98e858b8-f3f5-4339-b0a1-e82bb8abcba7", APIVersion:"v1", ResourceVersion:"3143", FieldPath:"spec.containers{cilium-operator}"}, Reason:"Started", Message:"Started container cilium-operator", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63776471315, loc:(*time.Location)(0x74aba00)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xc06b8e96a066a636, ext:1981261330731, loc:(*time.Location)(0x74aba00)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://kind-control-plane:6443/api/v1/namespaces/kube-system/events/cilium-operator-58f7855696-vxkx4.16c58ead917a3f4e": dial tcp 172.18.0.4:6443: connect: no route to host'(may retry after sleeping)
Dec 30 14:37:06 kind-worker2 kubelet[172]: E1230 14:37:06.309034     172 reflector.go:138] object-"kube-system"/"hubble-server-certs": Failed to watch *v1.Secret: failed to list *v1.Secret: Get "https://kind-control-plane:6443/api/v1/namespaces/kube-system/secrets?fieldSelector=metadata.name%3Dhubble-server-certs&resourceVersion=3126": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:37:13 kind-worker2 kubelet[172]: E1230 14:37:13.007773     172 controller.go:144] failed to ensure lease exists, will retry in 7s, error: Get "https://kind-control-plane:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/kind-worker2?timeout=10s": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:37:13 kind-worker2 kubelet[172]: I1230 14:37:13.007806     172 status_manager.go:566] "Failed to get status for pod" podUID=cdadd77d-9f75-49c6-9050-b4c954e6b6f5 pod="kube-system/cilium-tkq6w" error="Get \"https://kind-control-plane:6443/api/v1/namespaces/kube-system/pods/cilium-tkq6w\": dial tcp 172.18.0.4:6443: connect: no route to host"
Dec 30 14:37:13 kind-worker2 kubelet[172]: E1230 14:37:13.007809     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://kind-control-plane:6443/api/v1/nodes?fieldSelector=metadata.name%3Dkind-worker2&resourceVersion=3809": dial tcp 172.18.0.4:6443: connect: no route to host
Dec 30 14:37:13 kind-worker2 kubelet[172]: E1230 14:37:13.007911     172 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://kind-control-plane:6443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=3244": dial tcp 172.18.0.4:6443: connect: no route to host